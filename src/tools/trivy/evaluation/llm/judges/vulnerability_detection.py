"""Judge for evaluating CVE vulnerability detection accuracy."""

from pathlib import Path
from typing import Any

from .base import BaseJudge, JudgeResult


class VulnerabilityDetectionJudge(BaseJudge):
    """Evaluates accuracy of CVE vulnerability detection."""

    @property
    def dimension_name(self) -> str:
        return "vulnerability_detection"

    @property
    def weight(self) -> float:
        return 0.25  # 25% of overall score

    def collect_evidence(self) -> dict[str, Any]:
        """Collect evidence about vulnerability detection accuracy."""
        results = self.load_analysis_results()
        ground_truth = self.load_ground_truth()

        evidence = {
            "summary": {
                "repos_analyzed": len(results),
                "total_vulnerabilities_found": 0,
                "total_critical": 0,
                "total_high": 0,
            },
            "per_repo_results": [],
            "ground_truth_comparison": [],
            "sample_vulnerabilities": [],
        }

        for repo_name, data in results.items():
            summary = data.get("summary", {})
            vulns = data.get("vulnerabilities", [])

            evidence["summary"]["total_vulnerabilities_found"] += summary.get(
                "total_vulnerabilities", 0
            )
            evidence["summary"]["total_critical"] += summary.get("critical_count", 0)
            evidence["summary"]["total_high"] += summary.get("high_count", 0)

            repo_result = {
                "repo": repo_name,
                "vulnerabilities_found": summary.get("total_vulnerabilities", 0),
                "critical": summary.get("critical_count", 0),
                "high": summary.get("high_count", 0),
                "medium": summary.get("medium_count", 0),
                "low": summary.get("low_count", 0),
                "targets_scanned": summary.get("targets_scanned", 0),
                "fix_available_pct": summary.get("fix_available_pct", 0),
            }
            evidence["per_repo_results"].append(repo_result)

            # Compare with ground truth
            if repo_name in ground_truth:
                gt = ground_truth[repo_name]
                expected_vulns = gt.get("expected_vulnerabilities", {})

                comparison = {
                    "repo": repo_name,
                    "found": summary.get("total_vulnerabilities", 0),
                    "expected_min": expected_vulns.get("min", 0),
                    "expected_max": expected_vulns.get("max", 999),
                    "within_range": (
                        expected_vulns.get("min", 0)
                        <= summary.get("total_vulnerabilities", 0)
                        <= expected_vulns.get("max", 999)
                    ),
                    "required_packages": gt.get("required_packages", []),
                }

                # Check if required packages were detected
                if comparison["required_packages"]:
                    found_packages = set(v.get("package", "") for v in vulns)
                    comparison["packages_found"] = [
                        p for p in comparison["required_packages"] if p in found_packages
                    ]
                    comparison["packages_missing"] = [
                        p
                        for p in comparison["required_packages"]
                        if p not in found_packages
                    ]

                evidence["ground_truth_comparison"].append(comparison)

            # Sample first 3 vulnerabilities for review
            for vuln in vulns[:3]:
                evidence["sample_vulnerabilities"].append(
                    {
                        "id": vuln.get("id"),
                        "severity": vuln.get("severity"),
                        "package": vuln.get("package"),
                        "installed_version": vuln.get("installed_version"),
                        "fixed_version": vuln.get("fixed_version"),
                        "cvss_score": vuln.get("cvss_score"),
                        "age_days": vuln.get("age_days"),
                        "fix_available": vuln.get("fix_available"),
                    }
                )

        return evidence
    def evaluate(self) -> JudgeResult:
        """Run the evaluation pipeline.

        Delegates to base class implementation which:
        1. Collects evidence via collect_evidence()
        2. Builds prompt from template
        3. Invokes Claude for evaluation
        4. Parses response into JudgeResult
        """
        return super().evaluate()
