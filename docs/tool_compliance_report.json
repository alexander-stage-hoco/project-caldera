{
  "generated_at": "2026-02-04T18:49:30.057839+00:00",
  "summary": {
    "failed": 1,
    "passed": 13,
    "tool_count": 14
  },
  "tools": [
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/outputs/6e1a36b0-040d-4943-848f-767b01c548ba/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.35,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/llm/results/llm-eval-20260204-160701.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.24,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.81,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/outputs/6e1a36b0-040d-4943-848f-767b01c548ba/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 3.19,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.16,
          "evidence": [
            "Checked 161 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "devskim",
            "devskim"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.43,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 152.64,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.43,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.12,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.13,
          "evidence": [
            "rule_coverage.py",
            "severity_calibration.py",
            "security_focus.py",
            "detection_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.14,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.06,
          "evidence": [
            "api-security.json",
            "csharp.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.09,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.08,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.2,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "score",
            "decision",
            "dimensions",
            "total_score",
            "average_confidence",
            "combined_score",
            "programmatic_input"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.2,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_devskim_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 127.55,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.7,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 46.64,
          "evidence": [
            "Fixture: devskim_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.56,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "Adapter DevskimAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Tool 'devskim' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.18,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.49,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.75,
          "evidence": [
            "DevskimFinding"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 34.35,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.23,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "devskim",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No analysis output found - run with --run-analysis or execute 'make analyze'",
          "severity": "critical",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/results/checks.json",
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/results/evaluation_report.json",
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/results/llm_evaluation.json",
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/scorecard.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No LLM evaluation output found - run with --run-llm or execute 'make evaluate-llm'",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "LLM evaluation quality check skipped (no outputs)",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.06,
          "evidence": [
            "No output.json found"
          ],
          "message": "No output.json available",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.05,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Insufficient LLM judges: 0 found, minimum 4 required",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 0.31,
          "evidence": [
            "base.py __init__ missing evaluation_mode parameter"
          ],
          "message": "base.py missing evaluation_mode parameter",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.04,
          "evidence": [
            "synthetic.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Missing evaluation_report.json at uniform path",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Cannot validate schema - file missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Cannot check quality - file missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "Missing llm_evaluation.json at uniform path",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "Cannot validate schema - file missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "Cannot check - file missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "Cannot check quality - file missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.11,
          "evidence": [
            "src/tools/dotcover/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter compliance rule defined",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined - skipping registration check",
          "severity": "medium",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined - skipping schema table check",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined - skipping orchestrator wiring check",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter rule defined - skipping dbt staging model check",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No adapter defined for this tool",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No entity mappings defined for this tool",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 14.02,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.22,
          "evidence": [
            "Add pytest-cov>=4.0.0 to requirements.txt"
          ],
          "message": "pytest-cov not in requirements.txt",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dotcover",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.27,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.19,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.17,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "git-sizer",
            "git-sizer"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.34,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 121.15,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.75,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "integration_fit.py",
            "size_accuracy.py",
            "actionability.py",
            "threshold_quality.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 9.28,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: size_accuracy.py",
            "prompt: size_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.12,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_dir",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.09,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.32,
          "evidence": [
            "timestamp",
            "analysis_path",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.12,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.21,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_git_sizer_repo_level_only.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.47,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 49.14,
          "evidence": [
            "Fixture: git_sizer_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.41,
          "evidence": [
            "health_grade_valid",
            "metrics_non_negative",
            "violation_levels"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Adapter GitSizerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Tool 'git-sizer' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.18,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.14,
          "evidence": [
            "GitSizerMetric",
            "GitSizerViolation",
            "GitSizerLfsCandidate"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 13.89,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.26,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-sizer",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/outputs/9ad8b91b-0618-4351-9ed3-9a07fc72bb19/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.2,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/evaluation/llm/results/llm-eval-20260204-135934.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.21,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.19,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/outputs/9ad8b91b-0618-4351-9ed3-9a07fc72bb19/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "gitleaks",
            "gitleaks"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.31,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 119.79,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.08,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.06,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.8,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.76,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "false_positive.py",
            "secret_coverage.py",
            "detection_accuracy.py",
            "severity_classification.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 3.47,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.37,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary",
            "categories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.08,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.27,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.34,
          "evidence": [
            "src/tools/gitleaks/tests/unit/test_rollup_invariants.py",
            "src/sot-engine/dbt/tests/test_rollup_gitleaks_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.73,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 52.26,
          "evidence": [
            "Fixture: gitleaks_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.45,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Adapter GitleaksAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'gitleaks' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.53,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.64,
          "evidence": [
            "GitleaksSecret"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 14.5,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.33,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "gitleaks",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/outputs/6e1a36b0-040d-4943-848f-767b01c548ba/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 1.0,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.21,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.77,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/outputs/6e1a36b0-040d-4943-848f-767b01c548ba/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 17.0,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "layout-scanner",
            "layout-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.6,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 309.3,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.46,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.74,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "classification_reasoning.py",
            "hierarchy_consistency.py",
            "language_detection.py",
            "directory_taxonomy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.1,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: classification_reasoning.py",
            "prompt: classification_reasoning.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.08,
          "evidence": [
            "mixed-language.json",
            "edge-cases.json",
            "generated-code.json",
            "config-heavy.json",
            "vendor-heavy.json",
            "small-clean.json",
            "deep-nesting.json",
            "mixed-types.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.62,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "evaluated_count",
            "average_score",
            "summary",
            "checks",
            "repositories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.55,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.41,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.32,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_layout_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.74,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 61.47,
          "evidence": [
            "Fixture: layout_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.73,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Adapter LayoutAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.0,
          "evidence": [
            "Layout is ingested before TOOL_INGESTION_CONFIGS loop"
          ],
          "message": "layout-scanner handled specially as prerequisite tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.22,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.59,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.55,
          "evidence": [
            "LayoutFile",
            "LayoutDirectory"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 15.81,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.36,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "layout-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.87,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.24,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.33,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 12.15,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.12,
          "evidence": [
            "Checked 85 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "lizard",
            "lizard"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.64,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 167.25,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "hotspot_ranking.py",
            "ccn_accuracy.py",
            "function_detection.py",
            "statistics.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.57,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: ccn_accuracy.py",
            "prompt: ccn_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.39,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_path",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.31,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.3,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.8,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 87.98,
          "evidence": [
            "Fixture: lizard_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.99,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "Adapter LizardAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'lizard' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.51,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.42,
          "evidence": [
            "LizardFileMetric",
            "LizardFunctionMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 16.97,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.33,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "lizard",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/outputs/cpd-test-run/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.5,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.17,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.7,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/outputs/cpd-test-run/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.54,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.06,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "pmd-cpd",
            "pmd-cpd"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.4,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 134.82,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.91,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.75,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "duplication_accuracy.py",
            "actionability.py",
            "semantic_detection.py",
            "cross_file_detection.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 4.36,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: duplication_accuracy.py",
            "prompt: duplication_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.17,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.15,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.04,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "combined_score",
            "notes"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.04,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=WEAK_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.31,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_pmd_cpd_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.02,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 145.65,
          "evidence": [
            "Fixture: pmd_cpd_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.03,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Adapter PmdCpdAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'pmd-cpd' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.21,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.66,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.71,
          "evidence": [
            "PmdCpdFileMetric",
            "PmdCpdDuplication",
            "PmdCpdOccurrence"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 17.72,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.32,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "pmd-cpd",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/outputs/D5326F5E-3A72-46F3-8EA4-8D47E9EF6861/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.43,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.22,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.92,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/outputs/D5326F5E-3A72-46F3-8EA4-8D47E9EF6861/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 19.39,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.1,
          "evidence": [
            "Checked 71 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "roslyn-analyzers",
            "roslyn-analyzers"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.38,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 211.4,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.58,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.43,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.99,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.88,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "overall_quality.py",
            "integration_fit.py",
            "resource_management.py",
            "security_detection.py",
            "design_analysis.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 20.18,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.12,
          "evidence": [
            "clean-code.json",
            "resource-management.json",
            "dead-code.json",
            "csharp.json",
            "security-issues.json",
            "design-violations.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.43,
          "evidence": [
            "evaluation_id",
            "timestamp",
            "analysis_file",
            "decision",
            "score",
            "summary",
            "category_scores",
            "checks",
            "decision_reason"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.34,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.06,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.34,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.11,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.45,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_roslyn_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.79,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 109.24,
          "evidence": [
            "Fixture: roslyn_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.54,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Adapter RoslynAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Tool 'roslyn-analyzers' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.69,
          "evidence": [
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.41,
          "evidence": [
            "RoslynViolation"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.37,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 16.19,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.26,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "roslyn-analyzers",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/outputs/CC5F6CC7-7C19-4AD7-9C5C-6C92002ADEE9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 1.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/llm/results/llm-eval-20260204-175827.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.97,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.52,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/outputs/CC5F6CC7-7C19-4AD7-9C5C-6C92002ADEE9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.29,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.03,
          "evidence": [
            "Checked 23 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "scancode",
            "scancode"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.42,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 153.01,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.43,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.08,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.35,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "coverage_judge.py",
            "accuracy_judge.py",
            "actionability_judge.py",
            "risk_classification_judge.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 4.19,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy_judge.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.08,
          "evidence": [
            "multi-license.json",
            "mit-only.json",
            "gpl-mixed.json",
            "apache-bsd.json",
            "public-domain.json",
            "spdx-expression.json",
            "no-license.json",
            "dual-licensed.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.72,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "summary",
            "checks",
            "total_repositories",
            "reports"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.6,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.86,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "dimensions",
            "score",
            "total_score",
            "average_confidence",
            "decision",
            "programmatic_score",
            "combined_score"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.65,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.7,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.2,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scancode_repo_level_metrics.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.82,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 92.18,
          "evidence": [
            "Fixture: scancode_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.97,
          "evidence": [
            "paths",
            "confidence",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Adapter ScancodeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'scancode' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.21,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.16,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.86,
          "evidence": [
            "ScancodeFileLicense",
            "ScancodeSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 16.97,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.09,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scancode",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.68,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/llm/results/llm-eval-20260125-104034.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.26,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.87,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 5.47,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.12,
          "evidence": [
            "Checked 94 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "scc",
            "scc"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.58,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 150.01,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.18,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.6,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.75,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "error_messages.py",
            "documentation.py",
            "edge_cases.py",
            "directory_analysis.py",
            "integration_fit.py",
            "code_quality.py",
            "risk.py",
            "statistics.py",
            "comparative.py",
            "api_design.py"
          ],
          "message": "LLM judge count meets minimum (10 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 11.68,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: directory_analysis.py",
            "prompt: directory_analysis.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.22,
          "evidence": [
            "run_id",
            "timestamp",
            "dimensions",
            "total_score",
            "decision"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.18,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.27,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.1,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.43,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.92,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 112.99,
          "evidence": [
            "Fixture: scc_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.0,
          "evidence": [
            "paths",
            "ranges",
            "ratios",
            "required_fields"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "Adapter SccAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.25,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'scc' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.21,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.59,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.39,
          "evidence": [
            "SccFileMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 17.31,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.11,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scc",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/outputs/2D245F63-BD0B-4A90-8202-2742FB2E4712/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.34,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/llm/results/llm-eval-20260130-120000.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.18,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.72,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/outputs/2D245F63-BD0B-4A90-8202-2742FB2E4712/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 6.45,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.08,
          "evidence": [
            "Checked 65 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "semgrep",
            "semgrep"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.58,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 155.14,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.25,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.11,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.6,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "rule_coverage.py",
            "actionability.py",
            "security_detection.py",
            "smell_accuracy.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 14.18,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.1,
          "evidence": [
            "java.json",
            "go.json",
            "csharp.json",
            "rust.json",
            "javascript.json",
            "typescript.json",
            "python.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.32,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "analysis_path"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.32,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_semgrep_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.95,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 91.57,
          "evidence": [
            "Fixture: semgrep_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.4,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.25,
          "evidence": [],
          "message": "Adapter SemgrepAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.25,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'semgrep' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.64,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 14.82,
          "evidence": [
            "SemgrepSmell"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 17.2,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.23,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "semgrep",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/outputs/B16129A2-F8A9-4C9A-A347-365A8569418B/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.2,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/llm/results/llm-eval-20260130-120000.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.18,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.58,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/outputs/B16129A2-F8A9-4C9A-A347-365A8569418B/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 3.45,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.2.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "sonarqube",
            "sonarqube"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.35,
          "evidence": [
            "1.2.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 136.84,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.61,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.13,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.83,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "issue_accuracy.py",
            "integration_fit.py",
            "actionability.py",
            "coverage_completeness.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 8.78,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: issue_accuracy.py",
            "prompt: issue_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.1,
          "evidence": [
            "java-security.json",
            "typescript-duplication.json",
            "csharp-baseline.json",
            "python-mixed.json",
            "csharp-complex.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.35,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "analysis_path",
            "summary",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.39,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_sonarqube_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.95,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 161.09,
          "evidence": [
            "Fixture: sonarqube_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.52,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "Adapter SonarqubeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.28,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'sonarqube' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.21,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.69,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.76,
          "evidence": [
            "SonarqubeIssue",
            "SonarqubeMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 16.82,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.1,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "sonarqube",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.74,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.38,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.19,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "symbol-scanner",
            "symbol-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.36,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 125.68,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.07,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.08,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.42,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "call_relationship.py",
            "import_completeness.py",
            "integration.py",
            "symbol_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 5.75,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: call_relationship.py",
            "prompt: call_relationship.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.13,
          "evidence": [
            "metaprogramming.json",
            "csharp-tshock.json",
            "cross-module-calls.json",
            "deep-hierarchy.json",
            "encoding-edge-cases.json",
            "circular-imports.json",
            "type-checking-imports.json",
            "decorators-advanced.json",
            "dynamic-code-generation.json",
            "async-patterns.json",
            "nested-structures.json",
            "class-hierarchy.json",
            "simple-functions.json",
            "generators-comprehensions.json",
            "dataclasses-protocols.json",
            "deep-nesting-stress.json",
            "partial-syntax-errors.json",
            "unresolved-externals.json",
            "confusing-names.json",
            "modern-syntax.json",
            "large-file.json",
            "web-framework-patterns.json",
            "import-patterns.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.4,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "checks",
            "summary",
            "aggregate",
            "per_repo_results",
            "metadata",
            "regression"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.34,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.22,
          "evidence": [
            "src/sot-engine/dbt/models/staging/stg_lz_code_symbols.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.84,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 91.79,
          "evidence": [
            "Fixture: symbol_scanner_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.02,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.25,
          "evidence": [],
          "message": "Adapter SymbolScannerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Tool 'symbol-scanner' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.18,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.2,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.64,
          "evidence": [
            "CodeSymbol",
            "SymbolCall",
            "FileImport"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 14.56,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.36,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "symbol-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/outputs/9ad8b91b-0618-4351-9ed3-9a07fc72bb19/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.56,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/llm/results/synthetic-llm-eval.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.2,
          "evidence": [
            "score=4.0"
          ],
          "message": "LLM evaluation score meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.38,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/outputs/9ad8b91b-0618-4351-9ed3-9a07fc72bb19/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.6,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "trivy",
            "trivy"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.41,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 125.02,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.08,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.44,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.37,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "freshness_quality.py",
            "vulnerability_detection.py",
            "vulnerability_accuracy.py",
            "severity_accuracy.py",
            "iac_quality.py",
            "sbom_completeness.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 11.65,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: vulnerability_accuracy.py",
            "prompt: vulnerability_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.12,
          "evidence": [
            "dotnet-outdated.json",
            "js-fullstack.json",
            "vulnerable-npm.json",
            "iac-terraform.json",
            "no-vulnerabilities.json",
            "iac-misconfigs.json",
            "mixed-severity.json",
            "java-outdated.json",
            "critical-cves.json",
            "outdated-deps.json",
            "cfn-misconfigs.json",
            "k8s-misconfigs.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.23,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "classification",
            "overall_score",
            "summary",
            "checks",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.19,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.4,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.11,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.23,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_trivy_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.93,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 162.61,
          "evidence": [
            "Fixture: trivy_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.13,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Adapter TrivyAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'trivy' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.48,
          "evidence": [
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.17,
          "evidence": [
            "TrivyVulnerability",
            "TrivyTarget",
            "TrivyIacMisconfig"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 15.05,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (144 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.31,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "trivy",
      "status": "pass"
    }
  ],
  "tools_root": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools"
}