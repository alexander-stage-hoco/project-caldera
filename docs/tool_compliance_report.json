{
  "generated_at": "2026-02-05T23:23:53.442072+00:00",
  "summary": {
    "failed": 13,
    "passed": 1,
    "tool_count": 14
  },
  "tools": [
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 28.22,
          "evidence": [
            "Checking DevSkim CLI installation..."
          ],
          "message": "make analyze failed",
          "severity": "critical",
          "status": "fail",
          "stderr_summary": "You must install or update .NET to run this application.\n\nApp: /Users/alexander.stage/.dotnet/tools/devskim\nArchitecture: arm64\nFramework: 'Microsoft.NETCore.App', version '9.0.0' (arm64)\n.NET location: /usr/local/share/dotnet\n\nThe following frameworks were found:\n  10.0.1 at [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\n\nLearn more:\nhttps://aka.ms/dotnet/app-launch-failed\n\nTo install missing framework, download:\nhttps://aka.ms/dotnet-core-applaunch?framework=Microsoft.NETCore.App&framework_version=9.0.0&arch=arm64&rid=osx-arm64&os=osx.15\nmake[1]: *** [_check-devskim] Error 150",
          "stdout_summary": "Checking DevSkim CLI installation..."
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 24.1,
          "evidence": [
            "Checking DevSkim CLI installation..."
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "You must install or update .NET to run this application.\n\nApp: /Users/alexander.stage/.dotnet/tools/devskim\nArchitecture: arm64\nFramework: 'Microsoft.NETCore.App', version '9.0.0' (arm64)\n.NET location: /usr/local/share/dotnet\n\nThe following frameworks were found:\n  10.0.1 at [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\n\nLearn more:\nhttps://aka.ms/dotnet/app-launch-failed\n\nTo install missing framework, download:\nhttps://aka.ms/dotnet-core-applaunch?framework=Microsoft.NETCore.App&framework_version=9.0.0&arch=arm64&rid=osx-arm64&os=osx.15\nmake[1]: *** [_check-devskim] Error 150",
          "stdout_summary": "Checking DevSkim CLI installation..."
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 23.43,
          "evidence": [
            "Checking DevSkim CLI installation..."
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "You must install or update .NET to run this application.\n\nApp: /Users/alexander.stage/.dotnet/tools/devskim\nArchitecture: arm64\nFramework: 'Microsoft.NETCore.App', version '9.0.0' (arm64)\n.NET location: /usr/local/share/dotnet\n\nThe following frameworks were found:\n  10.0.1 at [/usr/local/share/dotnet/shared/Microsoft.NETCore.App]\n\nLearn more:\nhttps://aka.ms/dotnet/app-launch-failed\n\nTo install missing framework, download:\nhttps://aka.ms/dotnet-core-applaunch?framework=Microsoft.NETCore.App&framework_version=9.0.0&arch=arm64&rid=osx-arm64&os=osx.15\nmake[1]: *** [_check-devskim] Error 150",
          "stdout_summary": "Checking DevSkim CLI installation..."
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.22,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/outputs/6e1a36b0-040d-4943-848f-767b01c548ba/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 3.18,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.17,
          "evidence": [
            "Checked 161 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "devskim",
            "devskim"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.62,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 143.04,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.13,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.37,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.15,
          "evidence": [
            "rule_coverage.py",
            "severity_calibration.py",
            "security_focus.py",
            "detection_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.27,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.16,
          "evidence": [
            "api-security.json",
            "csharp.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.25,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.11,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.38,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "score",
            "decision",
            "dimensions",
            "total_score",
            "average_confidence",
            "combined_score",
            "programmatic_input"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.2,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_devskim_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 130.92,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.8,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 48.3,
          "evidence": [
            "Fixture: devskim_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.63,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Adapter DevskimAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.21,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Tool 'devskim' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.47,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.33,
          "evidence": [
            "DevskimFinding"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 38.85,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.26,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "devskim",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 130773.23,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-a5aecnrt \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit de062fd7e937bf79f0c0a9b45366d91ef014c7f7\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic\nFound test project: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/s\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 80.91,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--results-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-a5aecnrt \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-f_k5ji3r/evaluation_report.json\nEvaluation complete. Decision: PASS\nScore: 66.7% (2/3 passed)\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-f_k5ji3r/evaluation_report.json"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-f_k5ji3r/scorecard.md"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.19,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 53.54,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-a5aecnrt \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ttl32d6t/llm_evaluation.json \\\n\t\t--model opus-4.5 \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json\nLLM evaluation complete. Verdict: PASS\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ttl32d6t/llm_evaluation.json"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.12,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.07,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-a5aecnrt/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "dotcover",
            "dotcover"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.5,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 143.28,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.67,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.15,
          "evidence": [
            "false_positive.py",
            "actionability.py",
            "integration.py",
            "accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.39,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "run_id",
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "summary",
            "dimensions",
            "total_score"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.04,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.04,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.18,
          "evidence": [
            "src/tools/dotcover/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.71,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 115.91,
          "evidence": [
            "Fixture: dotcover_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.5,
          "evidence": [
            "coverage_bounds",
            "statement_invariants",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.44,
          "evidence": [],
          "message": "Adapter DotcoverAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Tool 'dotcover' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.16,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.85,
          "evidence": [
            "DotcoverAssemblyCoverage",
            "DotcoverTypeCoverage",
            "DotcoverMethodCoverage"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 40.79,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.23,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dotcover",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 1112.25,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running repository analysis...\n  REPO_PATH: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic\n  RUN_ID:    compliance\n  REPO_ID:   compliance\n  BRANCH:    main\n  COMMIT:    988008cd161b132ca2aa596b4f0eae76c565ab8c\nFound 5 git repositories under /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic/bloated\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7tzb791/bloated/output.json\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic/deep-history\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/too\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 69.19,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\n\n======================================================================\nGIT-SIZER EVALUATION REPORT\n======================================================================\n\nTimestamp: 2026-02-06T00:05:45.551581\nAnalysis:  /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7tzb791\n\n----------------------------------------------------------------------\nOVERALL SUMMARY\n----------------------------------------------------------------------\n  Total Checks: 28\n  Passed:       28 (100.0%)\n  Failed:       0 (0.0%)\n  Overall Score: 1.00/1.00\n  Decision:      STRONG_PASS\n\n----------------------------------------------------------------------\nCATEGORY BREAKDOWN\n----------------------------------------------------------------------\n  ACCURACY         8/\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.16,
          "evidence": [
            "score=1.0",
            "failed=0",
            "total=28"
          ],
          "message": "Evaluation score meets threshold (computed)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 73336.54,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "Running size_accuracy judge...\n  Score: 5/5 (weight: 35%)\nRunning threshold_quality judge...\n  Score: 4/5 (weight: 25%)\nRunning actionability judge...\n  Score: 4/5 (weight: 20%)\nRunning integration_fit judge...\n  Score: 5/5 (weight: 20%)",
          "stdout_summary": "Running LLM evaluation...\n\n======================================================================\nGIT-SIZER LLM EVALUATION REPORT\n======================================================================\n\nTimestamp: 2026-02-05T23:05:45.671841+00:00\nAnalysis:  /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7tzb791\nModel:     opus-4.5\n\n----------------------------------------------------------------------\nSUMMARY\n----------------------------------------------------------------------\n  Weighted Score: 4.55/5.0\n  Grade:          A\n  Verdict:        STRONG_PASS\n\n----------------------------------------------------------------------\nJUDGE RESULTS\n----------------------------------------------------------------------\n\n  SIZE_ACCURACY (weight: 35%)\n    Score:      5/5 (weighted: 1.\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.25,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.21,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7tzb791/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [
            "violations[0] missing required field: file_path",
            "violations[0] missing required field: rule_id"
          ],
          "message": "Data completeness issues detected",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "git-sizer",
            "git-sizer"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.4,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 129.48,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.08,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.42,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "integration_fit.py",
            "size_accuracy.py",
            "actionability.py",
            "threshold_quality.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 8.33,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: size_accuracy.py",
            "prompt: size_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.23,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_dir",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.09,
          "evidence": [
            "timestamp",
            "analysis_path",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.17,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_git_sizer_repo_level_only.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.76,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 46.5,
          "evidence": [
            "Fixture: git_sizer_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.59,
          "evidence": [
            "health_grade_valid",
            "metrics_non_negative",
            "violation_levels"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "Adapter GitSizerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.2,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Tool 'git-sizer' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.44,
          "evidence": [
            "GitSizerMetric",
            "GitSizerViolation",
            "GitSizerLfsCandidate"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 30.27,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.21,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-sizer",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 14780.06,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-e5iof6s4 \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 988008cd161b132ca2aa596b4f0eae76c565ab8c\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic\nUsing gitleaks: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/bin/gitleaks\nGit\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 71.41,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis-dir outputs/runs \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69\nGitleaks PoC Evaluation\n============================================================\nNo analysis files found in outputs/runs\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69/evaluation_report.json"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69/scorecard.md"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-g5b2ed69/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 63311.76,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--working-dir . \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json \\\n\t\t--model opus-4.5 \\\n\t\t--evaluation-mode synthetic\nLLM Evaluation for poc-gitleaks\nModel: opus-4.5\nWorking directory: .\nEvaluation mode: synthetic\n============================================================\n\nRunning 4 judges...\n\nRunning detection_accuracy evaluation...\n  Score: 1/5 (confidence: 0.99)\nRunning false_positive evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning secret_coverage evaluation...\n  Score: 1/5 (confidence: 0.95)\nRunning severity_classification evaluation...\n  Score: 1/5 (confidence: 0.95)\n\n============================================================\nRESULTS\n============\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-756egg84/llm_evaluation.json"
          ],
          "message": "LLM evaluation JSON missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.63,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-e5iof6s4/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 2.08,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.07,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "gitleaks",
            "gitleaks"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.4,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 128.93,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.06,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.09,
          "evidence": [
            "false_positive.py",
            "secret_coverage.py",
            "detection_accuracy.py",
            "severity_classification.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 3.25,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.06,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary",
            "categories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.19,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.33,
          "evidence": [
            "src/tools/gitleaks/tests/unit/test_rollup_invariants.py",
            "src/sot-engine/dbt/tests/test_rollup_gitleaks_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.63,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 51.08,
          "evidence": [
            "Fixture: gitleaks_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.41,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Adapter GitleaksAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.21,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "Tool 'gitleaks' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.18,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.48,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.18,
          "evidence": [
            "GitleaksSecret"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.33,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 31.38,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.41,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "gitleaks",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 164.77,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Setup complete!\nScanning synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-kdr_ws5e\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t \\\n\t\t--commit \"988008cd161b132ca2aa596b4f0eae76c565ab8c\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/eval-repos/synthetic\nFiles found: 143\nDirectories: 79\nScan duration: 16ms\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-kdr_ws5e/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 199.68,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Setup complete!\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4vh1c8kg /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate\nEvaluating output.json...\n  Score: 4.75/5.0 - STRONG_PASS\n  Checks: 33/36 passed\n\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4vh1c8kg/evaluation_report.json\n\nAggregate: 4.75/5.0 - STRONG_PASS"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4vh1c8kg/checks.json"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.24,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 274391.85,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Setup complete!\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--working-dir /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-kdr_ws5e/output.json \\\n\t\t--model opus-4.5 \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-f2s559lm/llm_evaluation.json \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json\nRunning full evaluation (4 judges)...\nRunning classification_reasoning evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning directory_taxonomy evaluation...\n  Score: 3/5 (confidence: 0.88)\nRunning hierarchy_consistency evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunnin\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.3,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.25,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-kdr_ws5e/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 9.44,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "layout-scanner",
            "layout-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.68,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 232.96,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.06,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.75,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "classification_reasoning.py",
            "hierarchy_consistency.py",
            "language_detection.py",
            "directory_taxonomy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.24,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: classification_reasoning.py",
            "prompt: classification_reasoning.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.08,
          "evidence": [
            "mixed-language.json",
            "edge-cases.json",
            "generated-code.json",
            "config-heavy.json",
            "vendor-heavy.json",
            "small-clean.json",
            "deep-nesting.json",
            "mixed-types.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.66,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "evaluated_count",
            "average_score",
            "summary",
            "checks",
            "repositories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.48,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.33,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_layout_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.9,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 58.37,
          "evidence": [
            "Fixture: layout_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.73,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.48,
          "evidence": [],
          "message": "Adapter LayoutAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.0,
          "evidence": [
            "Layout is ingested before TOOL_INGESTION_CONFIGS loop"
          ],
          "message": "layout-scanner handled specially as prerequisite tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.51,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.66,
          "evidence": [
            "LayoutFile",
            "LayoutDirectory"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.79,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 38.74,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.4,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "layout-scanner",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 444.28,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running function analysis on synthetic...\nLizard version: lizard 1.20.0\n\nAnalyzing synthetic...\n  Analyzing 63 files with 8 threads...\n\nFiles analyzed: 63\nFunctions found: 529\nTotal CCN: 1358\nAvg CCN: 2.57\nMax CCN: 26\nFunctions over threshold: 20\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-tak03mro/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 2464.77,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation (76 checks)...\nLizard version: lizard 1.20.0\n\nAnalyzing synthetic...\n  Analyzing 63 files with 8 threads...\n\nFiles analyzed: 63\nFunctions found: 529\nTotal CCN: 1358\nAvg CCN: 2.57\nMax CCN: 26\nFunctions over threshold: 20\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-w7324k8a/output.json\n\n================================================================================\n  LIZARD EVALUATION REPORT\n================================================================================\n\n  Timestamp: 2026-02-05T23:12:55.543123+00:00\n  Analysis:  /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-w7324k8a/output.json\n  Ground Truth: evaluation/ground-truth\n\n-------------------------------------------------------------------\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.43,
          "evidence": [
            "score=0.986",
            "failed=0",
            "total=None"
          ],
          "message": "Evaluation score meets threshold (computed)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 50401.13,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Running LLM evaluation (4 judges)...\n\n============================================================\nLLM Evaluation - Lizard Function Complexity Analysis\n============================================================\n\nRunning ccn_accuracy evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 2/5 (confidence: 0.45)\nRunning function_detection evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\nRunning statistics evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\nRunning hotspot_ranking evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\n\n============================================================\nEVALUATION SUMMARY\n==================================================\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.32,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.06,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-w7324k8a/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 11.11,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.1,
          "evidence": [
            "Checked 85 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "lizard",
            "lizard"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.66,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 179.85,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.96,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.59,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.58,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.6,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "hotspot_ranking.py",
            "ccn_accuracy.py",
            "function_detection.py",
            "statistics.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.75,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: ccn_accuracy.py",
            "prompt: ccn_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.6,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_path",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.26,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.28,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.88,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 86.68,
          "evidence": [
            "Fixture: lizard_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.63,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "Adapter LizardAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Tool 'lizard' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.49,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.04,
          "evidence": [
            "LizardFileMetric",
            "LizardFunctionMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 42.42,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.42,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "lizard",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 5859.05,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 6006.03,
          "evidence": [
            "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning programmatic evaluation (~28 checks)...\n======================================================================\nPMD CPD EVALUATION REPORT\n======================================================================\n\nAnalysis\u2026"
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "make[1]: *** [evaluate] Error 1",
          "stdout_summary": "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning programmatic evaluation (~28 checks)...\n======================================================================\nPMD CPD EVALUATION REPORT\n======================================================================\n\nAnalysis\u2026"
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 5871.44,
          "evidence": [
            "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning LLM evaluation (4 judges)..."
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 348, in <module>\n    main()\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 271, in main\n    report = run_llm_evaluation(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 93, in run_llm_evaluation\n    DuplicationAccuracyJudge(\nTypeError: BaseJudge.__init__() got an unexpected keyword argument 'analysis_path'\nmake[1]: *** [evaluate-llm] Error 1",
          "stdout_summary": "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning LLM evaluation (4 judges)..."
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.55,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-u7pgusvs/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.92,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "pmd-cpd",
            "pmd-cpd"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.55,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 215.13,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.39,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.6,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.77,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.13,
          "evidence": [
            "duplication_accuracy.py",
            "actionability.py",
            "semantic_detection.py",
            "cross_file_detection.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 5.16,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: duplication_accuracy.py",
            "prompt: duplication_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.17,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.37,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.19,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.2,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "combined_score",
            "notes"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=WEAK_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.38,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_pmd_cpd_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.38,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 155.7,
          "evidence": [
            "Fixture: pmd_cpd_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.28,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.44,
          "evidence": [],
          "message": "Adapter PmdCpdAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.29,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Tool 'pmd-cpd' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.27,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.76,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.62,
          "evidence": [
            "PmdCpdFileMetric",
            "PmdCpdDuplication",
            "PmdCpdOccurrence"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.72,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 38.24,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.29,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "pmd-cpd",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 14016.3,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 8061.05,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-2yx809vt/checks.json"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.31,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 91086.29,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.29,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.34,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hs5fgawi/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 19.85,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 62 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "roslyn-analyzers",
            "roslyn-analyzers"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.42,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 231.0,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.45,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.12,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.77,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.13,
          "evidence": [
            "overall_quality.py",
            "integration_fit.py",
            "resource_management.py",
            "security_detection.py",
            "design_analysis.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 12.82,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.09,
          "evidence": [
            "clean-code.json",
            "resource-management.json",
            "dead-code.json",
            "csharp.json",
            "security-issues.json",
            "design-violations.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.24,
          "evidence": [
            "evaluation_id",
            "timestamp",
            "analysis_file",
            "decision",
            "score",
            "summary",
            "category_scores",
            "checks",
            "decision_reason"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.09,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.38,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_roslyn_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.03,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 140.09,
          "evidence": [
            "Fixture: roslyn_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.61,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.55,
          "evidence": [],
          "message": "Adapter RoslynAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.25,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Tool 'roslyn-analyzers' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.22,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.72,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.06,
          "evidence": [
            "RoslynViolation"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 40.25,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.35,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "roslyn-analyzers",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 227.19,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running license analysis on synthetic...\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/eval-repos/synthetic\nLicenses found: ['Apache-2.0', 'BSD-3-Clause', 'GPL-2.0-only WITH Classpath-exception-2.0', 'GPL-3.0-only', 'LGPL-2.1-only', 'MIT', 'Unlicense']\nOverall risk: critical\nFiles with licenses: 23\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-mmnji1m5/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 120.5,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\nLicense Analysis Evaluation\n============================================================\n\nno-license: 32/32 (PASS)\napache-bsd: 32/32 (PASS)\nmit-only: 32/32 (PASS)\napache-bsd: 32/32 (PASS)\ngpl-mixed: 32/32 (PASS)\nmulti-license: 32/32 (PASS)\n\n============================================================\nSummary\n============================================================\nRepositories evaluated: 6\nTotal checks: 192\nPassed: 192\nFailed: 0\nOverall pass rate: 100.0%\n\nScorecard saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.json\nMarkdown scorecard saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.md\n\nResults saved to: evaluation/results/evaluati\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-0b3x818v/scorecard.md"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-0b3x818v/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-0b3x818v/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-0b3x818v/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 9284.88,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running LLM-as-a-Judge evaluation...\nLLM Evaluation for scancode\nModel: opus-4.5\nWorking directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode\n============================================================\n\nRunning 4 judges...\n\nRunning accuracy evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning coverage evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning actionability evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning risk_classification evaluation...\n  Score: 3/5 (confidence: 0.50)\n\n============================================================\nRESULTS\n============================================================\nTotal Score: 3.00\nDecision: WEAK_PASS\n\nResults saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evalu\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.65,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.33,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-mmnji1m5/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.18,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.04,
          "evidence": [
            "Checked 23 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "scancode",
            "scancode"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.42,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 119.22,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.35,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "coverage_judge.py",
            "accuracy_judge.py",
            "actionability_judge.py",
            "risk_classification_judge.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 3.53,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy_judge.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.07,
          "evidence": [
            "multi-license.json",
            "mit-only.json",
            "gpl-mixed.json",
            "apache-bsd.json",
            "public-domain.json",
            "spdx-expression.json",
            "no-license.json",
            "dual-licensed.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.41,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "summary",
            "checks",
            "total_repositories",
            "reports"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.33,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.85,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "dimensions",
            "score",
            "total_score",
            "average_confidence",
            "decision",
            "programmatic_score",
            "combined_score"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.58,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.54,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.16,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scancode_repo_level_metrics.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.66,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 85.97,
          "evidence": [
            "Fixture: scancode_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.58,
          "evidence": [
            "paths",
            "confidence",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.42,
          "evidence": [],
          "message": "Adapter ScancodeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Tool 'scancode' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.27,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.18,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.75,
          "evidence": [
            "ScancodeFileLicense",
            "ScancodeSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.32,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 33.87,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.36,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scancode",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 168.13,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running directory analysis on synthetic...\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/eval-repos/synthetic\nUsing scc: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/bin/scc\nFiles found: 63\nTotal files: 63\nTotal lines: 7,666\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-20fpxmxi/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 109.44,
          "evidence": [
            "Running programmatic evaluation..."
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/scripts/evaluate.py\", line 17, in <module>\n    from scripts.analyze import _resolve_commit\nImportError: cannot import name '_resolve_commit' from 'scripts.analyze' (/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/scripts/analyze.py)\nmake[1]: *** [evaluate] Error 1",
          "stdout_summary": "Running programmatic evaluation..."
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 208051.24,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running LLM-as-a-Judge evaluation...\n============================================================\nLLM-as-a-Judge Evaluation\n============================================================\nMode: full\nModel: opus-4.5\nWorking Directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc\n============================================================\n\nRegistering all judges (10 dimensions)...\n\nRunning code_quality evaluation...\n  Score: 4/5 (confidence: 0.85)\nRunning integration_fit evaluation...\n  Score: 4/5 (confidence: 0.92)\nRunning documentation evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning edge_cases evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning error_messages evaluation...\n  Score: 4/5 (confidence: 0.85)\nRunning api_design evaluation...\n  Score: 4/5 (confi\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.44,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.05,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-20fpxmxi/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 4.94,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.11,
          "evidence": [
            "Checked 94 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "scc",
            "scc"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.55,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 148.59,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.8,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.49,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.75,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "error_messages.py",
            "documentation.py",
            "edge_cases.py",
            "directory_analysis.py",
            "integration_fit.py",
            "code_quality.py",
            "risk.py",
            "statistics.py",
            "comparative.py",
            "api_design.py"
          ],
          "message": "LLM judge count meets minimum (10 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 9.81,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: directory_analysis.py",
            "prompt: directory_analysis.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.17,
          "evidence": [
            "run_id",
            "timestamp",
            "dimensions",
            "total_score",
            "decision"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.14,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.12,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.09,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.28,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.78,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 90.52,
          "evidence": [
            "Fixture: scc_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.31,
          "evidence": [
            "paths",
            "ranges",
            "ratios",
            "required_fields"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "Adapter SccAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.2,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Tool 'scc' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.5,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.55,
          "evidence": [
            "SccFileMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 38.46,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.36,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scc",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 5664.8,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-tbo8fkk4\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"988008cd161b132ca2aa596b4f0eae76c565ab8c\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\nFiles analyzed: 58\nSmells found: 193\nDuration: 4304m\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 247.66,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nRunning programmatic evaluation (~28 checks)...\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-llj54zpn /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-tbo8fkk4/output.json \\\n\t\t--ground-truth evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-llj54zpn/evaluation_report.json\n\n\u001b[36m======================================================================\u001b[0m\n\u001b[36m\u001b[1m  SEMGREP EVALUATION REPORT\u001b[0m\n\u001b[36m====================\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-llj54zpn/checks.json"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.13,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 83098.64,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "[DEBUG] Looking for analysis files in: outputs\n  [DEBUG] Found 12 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: outputs\n  [DEBUG] Found 12 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Load\u2026",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-tbo8fkk4\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"988008cd161b132ca2aa596b4f0eae76c565ab8c\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\nFiles analyzed: 58\nSmells found: 193\nDuration: 3466m\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.39,
          "evidence": [
            "FAIL"
          ],
          "message": "LLM evaluation decision below required threshold",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.98,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-tbo8fkk4/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 5.42,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 65 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "semgrep",
            "semgrep"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.67,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 181.79,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.65,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.78,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.13,
          "evidence": [
            "rule_coverage.py",
            "actionability.py",
            "security_detection.py",
            "smell_accuracy.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 20.18,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.1,
          "evidence": [
            "java.json",
            "go.json",
            "csharp.json",
            "rust.json",
            "javascript.json",
            "typescript.json",
            "python.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.19,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.09,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "analysis_path",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "FAIL"
          ],
          "message": "LLM evaluation failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.27,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_semgrep_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.59,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 127.3,
          "evidence": [
            "Fixture: semgrep_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.53,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.48,
          "evidence": [],
          "message": "Adapter SemgrepAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "Tool 'semgrep' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.55,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.39,
          "evidence": [
            "SemgrepSmell"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.7,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 36.87,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.37,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "semgrep",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 159902.65,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/eval-repos/synthetic \\\n\t\t--project-key synthetic \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-ndg8e3cy/output.json \\\n\t\t--sonarqube-url http://localhost:9000 \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"988008cd161b132ca2aa596b4f0eae76c565ab8c\" \\\n\t\t \\\n\t\t \\\n\t\t\n\u001b[2m2026-02-05T23:21:08.296614Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting SonarQube container  \u001b[0m \u001b[36mcompose_file\u001b[0m=\u001b[35m/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/docker-compose.yml\u001b[0m\n\u001b[2m2026-02-05T23:21:08.826699Z\u001b[0m [\u001b[3\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 210.75,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ie3vfbp4 /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-ndg8e3cy/output.json \\\n\t\t--ground-truth evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ie3vfbp4/evaluation_report.json\n\u001b[36m\u001b[1m\nRunning programmatic evaluation...\u001b[0m\n\n\u001b[35m======================================================================\u001b[0m\n\u001b[35m\u001b[1m  SONARQUBE EVALUATION REPORT\u001b[0m\n\u001b[35m======================================================================\u001b[0m\n\n\u001b[34m\u001b[1mSUMMARY\u001b[0m\n\u001b[34m-----------------------------------\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ie3vfbp4/checks.json"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.38,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 212.53,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running LLM evaluation (3 judges)...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.llm_evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-ndg8e3cy/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-540dqx79/llm_evaluation.json \\\n\t\t--model opus-4.5 \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json\n\u001b[36m\u001b[1m\nRunning LLM evaluation...\u001b[0m\n  Running issue_accuracy judge... \u001b[31m2/5\u001b[0m (conf: 80%)\n  Running coverage_completeness judge... \u001b[32m5/5\u001b[0m (conf: 85%)\n  Running actionability judge... \u001b[32m5/5\u001b[0m (conf: 75%)\n\n\u001b[35m======================================================================\u001b[0m\n\u001b[35m\u001b[1m  SONARQUBE LLM EVALUATION REPORT\u001b[0m\n\u001b[35m====\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.17,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.75,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-ndg8e3cy/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 10.32,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.2.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "sonarqube",
            "sonarqube"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.48,
          "evidence": [
            "1.2.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 156.98,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.12,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.85,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.14,
          "evidence": [
            "issue_accuracy.py",
            "integration_fit.py",
            "actionability.py",
            "coverage_completeness.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 9.4,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: issue_accuracy.py",
            "prompt: issue_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [
            "java-security.json",
            "typescript-duplication.json",
            "csharp-baseline.json",
            "python-mixed.json",
            "csharp-complex.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.06,
          "evidence": [
            "timestamp",
            "analysis_path",
            "summary",
            "dimensions",
            "model",
            "score",
            "decision",
            "programmatic_input",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.72,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_sonarqube_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.07,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 209.76,
          "evidence": [
            "Fixture: sonarqube_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.53,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "Adapter SonarqubeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.25,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "Tool 'sonarqube' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.26,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.65,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.26,
          "evidence": [
            "SonarqubeIssue",
            "SonarqubeMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.42,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 39.87,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.37,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "sonarqube",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 850.53,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running symbol extraction on synthetic...\nSymbol Scanner v0.1.0\n\nAnalyzing synthetic...\nRepository: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic\n\nFiles analyzed: 25\nSymbols found: 609\n  - Functions: 200\n  - Classes: 110\n  - Methods: 286\n  - Variables: 13\nCalls found: 615\n  - Direct: 306\n  - Dynamic: 284\n  - Async: 25\n  - Resolved: 137\n    - Same file: 137\n    - Cross file: 0\n  - Unresolved: 478\nImports found: 63\n  - Static: 58\n  - Dynamic: 0\nErrors: 1\n\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-m6z4zn_b/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 1602.9,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "Warning: Repository csharp-tshock not found at /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic/csharp-tshock\n  Minor regression: 99.77% -> 99.07% (within threshold)",
          "stdout_summary": "Running programmatic evaluation...\nSymbol Scanner v0.1.0\n\nAnalyzing synthetic...\nRepository: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic\n\nFiles analyzed: 25\nSymbols found: 609\n  - Functions: 200\n  - Classes: 110\n  - Methods: 286\n  - Variables: 13\nCalls found: 615\n  - Direct: 306\n  - Dynamic: 284\n  - Async: 25\n  - Resolved: 137\n    - Same file: 137\n    - Cross file: 0\n  - Unresolved: 478\nImports found: 63\n  - Static: 58\n  - Dynamic: 0\nErrors: 1\n\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-gd2n3n5b/output.json\nRunning evaluation in analysis mode...\nGround truth: evaluation/ground-truth\nRepos dir: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/syntheti\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.51,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 131.63,
          "evidence": [
            "Running LLM evaluation (4 judges)..."
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "usage: orchestrator.py [-h] [--analysis ANALYSIS] [--output OUTPUT]\n                       [--model MODEL]\n                       [--programmatic-results PROGRAMMATIC_RESULTS]\n                       [--focused]\norchestrator.py: error: unrecognized arguments: --working-dir .\nmake[1]: *** [evaluate-llm] Error 2",
          "stdout_summary": "Running LLM evaluation (4 judges)..."
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.57,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-gd2n3n5b/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 18.06,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "symbol-scanner",
            "symbol-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.55,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 164.86,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.71,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.09,
          "evidence": [
            "call_relationship.py",
            "import_completeness.py",
            "integration.py",
            "symbol_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 5.63,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: call_relationship.py",
            "prompt: call_relationship.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.12,
          "evidence": [
            "metaprogramming.json",
            "csharp-tshock.json",
            "cross-module-calls.json",
            "deep-hierarchy.json",
            "encoding-edge-cases.json",
            "circular-imports.json",
            "type-checking-imports.json",
            "decorators-advanced.json",
            "dynamic-code-generation.json",
            "async-patterns.json",
            "nested-structures.json",
            "class-hierarchy.json",
            "simple-functions.json",
            "generators-comprehensions.json",
            "dataclasses-protocols.json",
            "deep-nesting-stress.json",
            "partial-syntax-errors.json",
            "unresolved-externals.json",
            "confusing-names.json",
            "modern-syntax.json",
            "large-file.json",
            "web-framework-patterns.json",
            "import-patterns.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.23,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.48,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "checks",
            "summary",
            "aggregate",
            "per_repo_results",
            "metadata",
            "regression"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.28,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.18,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.17,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.21,
          "evidence": [
            "src/sot-engine/dbt/models/staging/stg_lz_code_symbols.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.71,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 88.72,
          "evidence": [
            "Fixture: symbol_scanner_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.68,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Adapter SymbolScannerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'symbol-scanner' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.19,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.57,
          "evidence": [
            "CodeSymbol",
            "SymbolCall",
            "FileImport"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.17,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 15.42,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.53,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "symbol-scanner",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 3073.02,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-6b66p6a_ \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 988008cd161b132ca2aa596b4f0eae76c565ab8c \\\n\t\t--timeout 600\n\u001b[2m2026-02-05T23:23:49.878488Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting trivy analysis       \u001b[0m \u001b[36mrepo_name\u001b[0m=\u001b[35msynthetic\u001b[0m \u001b[36mrepo_path\u001b[0m=\u001b[35m/Users/alexander.stage/Projects/2026-01-24-Pro\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 108.13,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python scripts/evaluate.py --output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-xclj9dps/\nEvaluated 0 files"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.15,
          "evidence": [
            "missing decision and summary score"
          ],
          "message": "Evaluation decision missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 119.15,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-6b66p6a_/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-94mqf4q5/llm_evaluation.json\nRunning vulnerability_accuracy evaluation...\n  Ground truth assertions failed: 1 failures"
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/llm/orchestrator.py\", line 198, in <module>\n    main()\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/llm/orchestrator.py\", line 171, in main\n    result = evaluator.evaluate()\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/shared/evaluation/orchestrator.py\", line 189, in evaluate\n    result = judge.evaluate()\n             ^^^^^^^^^^^^^^^^\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/llm/judges/vulnerability_a\u2026",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-6b66p6a_/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-94mqf4q5/llm_evaluation.json\nRunning vulnerability_accuracy evaluation...\n  Ground truth assertions failed: 1 failures"
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.72,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-6b66p6a_/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 13.76,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "trivy",
            "trivy"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.79,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 159.25,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.56,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.09,
          "evidence": [
            "freshness_quality.py",
            "vulnerability_detection.py",
            "vulnerability_accuracy.py",
            "severity_accuracy.py",
            "iac_quality.py",
            "sbom_completeness.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 10.67,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: vulnerability_accuracy.py",
            "prompt: vulnerability_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [
            "dotnet-outdated.json",
            "js-fullstack.json",
            "vulnerable-npm.json",
            "iac-terraform.json",
            "no-vulnerabilities.json",
            "iac-misconfigs.json",
            "mixed-severity.json",
            "java-outdated.json",
            "critical-cves.json",
            "outdated-deps.json",
            "cfn-misconfigs.json",
            "k8s-misconfigs.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.27,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.4,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "classification",
            "overall_score",
            "summary",
            "checks",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.17,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.26,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.21,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.19,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_trivy_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.7,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 167.54,
          "evidence": [
            "Fixture: trivy_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.65,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Adapter TrivyAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'trivy' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.49,
          "evidence": [
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.16,
          "evidence": [
            "TrivyVulnerability",
            "TrivyTarget",
            "TrivyIacMisconfig"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.16,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 15.86,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (158 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.31,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "trivy",
      "status": "fail"
    }
  ],
  "tools_root": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools"
}