{
  "generated_at": "2026-02-08T09:58:41.128978+00:00",
  "summary": {
    "failed": 12,
    "passed": 4,
    "tool_count": 16
  },
  "tools": [
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 1162.16,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/eval-repos/synthetic\nProjects found: 4\nPackage dependencies: 9\nProject references: 6\nCircular dependencies: 0\nOutput: /var\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 129.34,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--results-dir outputs/f23f9a48-fb85-4c81-8e04-da14641d23b3/ \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-12muqsb2/evaluation_report.json\nEvaluation complete. Decision: FAIL\nScore: 93.8% (15/16 passed)"
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "make[1]: *** [evaluate] Error 1",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--results-dir outputs/f23f9a48-fb85-4c81-8e04-da14641d23b3/ \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-12muqsb2/evaluation_report.json\nEvaluation complete. Decision: FAIL\nScore: 93.8% (15/16 passed)"
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 82575.01,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "[DEBUG] Looking for analysis files in: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo\n  [DEBUG] Found 1 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo\n  [DEBUG] Found 1 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo\n  [DEBUG] Found 1 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo\n  [DEBUG] Found 1 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-\u2026",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-pn80fg8s/llm_evaluation.json \\\n\t\t--model opus-4.5\nLLM Evaluation for dependensee\nModel: opus-4.5\nWorking directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee\nOutput directory: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo\n============================================================\n\nRunning full evaluation (4 judges)...\nRegistered 4 judges\n\nRunning project_detection evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning dependency_accuracy evaluation...\n  Score:\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.85,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.58,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-pod_83yo/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.4,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.03,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.03,
          "evidence": [
            "dependensee",
            "dependensee"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.56,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 218.46,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.67,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.25,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.62,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.41,
          "evidence": [
            "project_detection.py",
            "circular_detection.py",
            "graph_quality.py",
            "dependency_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 12.89,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: dependency_accuracy.py",
            "prompt: dependency_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.12,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.09,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.16,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.12,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.1,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.31,
          "evidence": [
            "src/tools/dependensee/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 227.83,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 4.2,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 97.67,
          "evidence": [
            "Fixture: dependensee_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.35,
          "evidence": [
            "paths",
            "required_fields"
          ],
          "message": "All 2 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.76,
          "evidence": [],
          "message": "Adapter DependenseeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.47,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "Tool 'dependensee' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.4,
          "evidence": [
            "stg_dependensee_package_refs.sql",
            "stg_dependensee_projects.sql",
            "stg_dependensee_project_refs.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.35,
          "evidence": [
            "stg_dependensee_package_refs.sql",
            "stg_dependensee_projects.sql",
            "stg_dependensee_project_refs.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 13.56,
          "evidence": [
            "DependenseeProject",
            "DependenseeProjectReference",
            "DependenseePackageReference"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.06,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 76.28,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (200 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.45,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dependensee",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 2514.38,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "devskim 1.0.70+d69541fde7",
          "stdout_summary": "Checking DevSkim CLI installation...\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hpq2_s_o\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\" \\\n\t\t--custom-rules \"rules/custom\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/eval-repos/synthetic\nFiles analyzed: 16\nIssues found: 50\nDuration: 1899ms\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compl\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 282.91,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "devskim 1.0.70+d69541fde7",
          "stdout_summary": "Checking DevSkim CLI installation...\nSetup complete!\nRunning programmatic evaluation...\n\n\u001b[36m======================================================================\u001b[0m\n\u001b[36m\u001b[1m  DEVSKIM EVALUATION REPORT\u001b[0m\n\u001b[36m======================================================================\u001b[0m\n\n\u001b[34m\u001b[1mSUMMARY\u001b[0m\n\u001b[34m----------------------------------------\u001b[0m\n  Total Checks:  30\n  Passed:        \u001b[32m29\u001b[0m\n  Failed:        \u001b[31m1\u001b[0m\n  Overall Score: \u001b[32m\u001b[1m91.1%\u001b[0m\n\n\u001b[34m\u001b[1mSCORE BY CATEGORY\u001b[0m\n\u001b[34m----------------------------------------\u001b[0m\n  accuracy        \u001b[32m100.0%\u001b[0m  (8/8 passed)\n  coverage        \u001b[32m93.0%\u001b[0m  (8/8 passed)\n  edge_cases      \u001b[32m80.0%\u001b[0m  (7/8 passed)\n  integration_fit \u001b[32m100.0%\u001b[0m  (1/1 passed)\n  output_quality  \u001b[32m100.0%\u001b[0m  (1/1 passed)\n  per\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ob92maxl/scorecard.md",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ob92maxl/checks.json"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ob92maxl/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ob92maxl/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ob92maxl/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 80959.22,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "devskim 1.0.70+d69541fde7\n<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Checking DevSkim CLI installation...\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hpq2_s_o\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\" \\\n\t\t--custom-rules \"rules/custom\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/eval-repos/synthetic\nFiles analyzed: 16\nIssues found: 50\nDuration: 1654ms\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compl\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-c1fv_fk0/llm_evaluation.json"
          ],
          "message": "LLM evaluation JSON missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.54,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hpq2_s_o/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 2.44,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.2,
          "evidence": [
            "Checked 18 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.04,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.04,
          "evidence": [
            "devskim",
            "devskim"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 1.05,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 277.69,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.64,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.46,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.15,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.72,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.06,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.71,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.22,
          "evidence": [
            "rule_coverage.py",
            "severity_calibration.py",
            "security_focus.py",
            "detection_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 12.64,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.32,
          "evidence": [
            "api-security.json",
            "deserialization.json",
            "xxe.json",
            "csharp.json",
            "clean.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.04,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.37,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.19,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.11,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "score",
            "decision",
            "dimensions",
            "total_score",
            "average_confidence",
            "combined_score",
            "programmatic_input"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.09,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.38,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_devskim_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 3.52,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 121.01,
          "evidence": [
            "Fixture: devskim_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.74,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.78,
          "evidence": [],
          "message": "Adapter DevskimAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.37,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.61,
          "evidence": [],
          "message": "Tool 'devskim' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.28,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.79,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 17.33,
          "evidence": [
            "DevskimFinding"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.11,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 55.88,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (200 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 1.49,
          "evidence": [
            "coverage=80.7%",
            "threshold=80%"
          ],
          "message": "Test coverage 80.7% >= 80% threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "devskim",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 151199.11,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-guh5dlbx \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/synthetic\nFound test project: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/eval-repos/s\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 224.7,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--results-dir outputs/dotcover-test-run \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-zbxemixd/evaluation_report.json\nScorecard JSON saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/scorecard.json\nScorecard Markdown saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/scorecard.md\nEvaluation complete. Decision: PASS\nScore: 100.0% (19/19 passed)\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-zbxemixd/evaluation_report.json"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.31,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 175.74,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-guh5dlbx \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-o0u2aeza/llm_evaluation.json \\\n\t\t--model opus-4.5 \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json\nLLM evaluation complete. Verdict: PASS\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-o0u2aeza/llm_evaluation.json"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.4,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.18,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-guh5dlbx/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.88,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.04,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.04,
          "evidence": [
            "dotcover",
            "dotcover"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 1.13,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 283.1,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.13,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.21,
          "evidence": [
            "false_positive.py",
            "actionability.py",
            "integration.py",
            "accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 21.62,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.05,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 1.03,
          "evidence": [
            "src/tools/dotcover/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 7.37,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 470.0,
          "evidence": [
            "Fixture: dotcover_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 2.4,
          "evidence": [
            "coverage_bounds",
            "statement_invariants",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 2.18,
          "evidence": [],
          "message": "Adapter DotcoverAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.93,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "Tool 'dotcover' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.83,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.27,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 31.1,
          "evidence": [
            "DotcoverAssemblyCoverage",
            "DotcoverTypeCoverage",
            "DotcoverMethodCoverage"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.11,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 118.39,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.82,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dotcover",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 7388.17,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running authorship analysis on synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python scripts/analyze.py /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/eval-repos/synthetic --output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-bugzz6rh/output.json\n============================================================\ngit-fame Authorship Analysis\n============================================================\nFound 5 repositories to analyze\n\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/eval-repos/synthetic/balanced...\n  Results: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-bugzz6rh/output.json\n  Authors: 4\n  Total LOC: 994\n  Bus Factor: 2\n  HHI Index: 0.2500\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 4952.05,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python scripts/evaluate.py\n============================================================\ngit-fame Programmatic Evaluation\n============================================================\n\nUsing output directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/outputs/f23f9a48-fb85-4c81-8e04-da14641d23b3\nRunning evaluation checks...\n\n1. Output Quality checks...\n   Score: 5.0/5.0 (6/6 passed)\n2. Authorship Accuracy checks...\n   Score: 5.0/5.0 (8/8 passed)\n3. Reliability checks...\n   Score: 5.0/5.0 (4/4 passed)\n4. Performance checks...\n   Score: 5.0/5.0 (4/4 passed)\n5. Integration Fit checks...\n   Score: 5.0/5.0 (4/4 passed)\n6. Installation checks...\n   Score: 5.0/5\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-cifyw_j0/scorecard.md"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-cifyw_j0/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-cifyw_j0/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-cifyw_j0/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 128181.08,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Running LLM-as-a-Judge evaluation...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator --model opus-4.5 --output evaluation/results/llm_evaluation.json\nLLM Evaluation for git-fame\nModel: opus-4.5\nWorking directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame\nOutput directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/outputs\n============================================================\n\nRunning full evaluation (6 judges)...\nRegistered 6 judges\n\nRunning authorship_quality evaluation...\n  Score: 4/5 (confidence: 0.78)\nRunning bus_factor_accuracy evaluation...\n  Score: 4/5 (confidence: 0.88)\nRunning concentration_metrics evaluation...\n  Score: 5/5 (confidence: 0.95)\nRu\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-5pmt0f7l/llm_evaluation.json"
          ],
          "message": "LLM evaluation JSON missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.74,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-bugzz6rh/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.49,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.05,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.05,
          "evidence": [
            "git-fame",
            "git-fame"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.84,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 170.99,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 2.61,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.48,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.19,
          "evidence": [
            "integration_readiness.py",
            "concentration_metrics.py",
            "evidence_quality.py",
            "authorship_quality.py",
            "utils.py",
            "bus_factor_accuracy.py",
            "output_completeness.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 20.36,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: authorship_quality.py",
            "prompt: authorship_quality.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.13,
          "evidence": [
            "synthetic.json",
            "multi-author.json",
            "bus-factor-1.json",
            "balanced.json",
            "multi-branch.json",
            "single-author.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.09,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "overall_score",
            "classification",
            "summary",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.11,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.1,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.36,
          "evidence": [
            "src/tools/git-fame/tests/scripts/test_analyze.py",
            "src/tools/git-fame/tests/scripts/test_authorship_accuracy_checks.py",
            "src/tools/git-fame/tests/scripts/test_output_quality_checks.py",
            "src/tools/git-fame/tests/scripts/test_reliability_checks.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 4.14,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 121.83,
          "evidence": [
            "Fixture: git_fame_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.72,
          "evidence": [
            "hhi_valid",
            "ownership_sums_100",
            "bus_factor_valid"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.99,
          "evidence": [],
          "message": "Adapter GitFameAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.53,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.59,
          "evidence": [],
          "message": "Tool 'git-fame' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.69,
          "evidence": [
            "stg_lz_git_fame_authors.sql",
            "stg_lz_git_fame_summary.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.55,
          "evidence": [
            "stg_lz_git_fame_authors.sql",
            "stg_lz_git_fame_summary.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 12.67,
          "evidence": [
            "GitFameAuthor",
            "GitFameSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.77,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 34.85,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.42,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-fame",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 2420.39,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running repository analysis...\n  REPO_PATH: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic\n  RUN_ID:    compliance\n  REPO_ID:   compliance\n  BRANCH:    main\n  COMMIT:    2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\nFound 5 git repositories under /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic/bloated\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-iwmjts2u/bloated/output.json\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/eval-repos/synthetic/deep-history\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/too\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 172.78,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\n\n======================================================================\nGIT-SIZER EVALUATION REPORT\n======================================================================\n\nTimestamp: 2026-02-08T10:42:40.030830\nAnalysis:  /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-iwmjts2u\n\n----------------------------------------------------------------------\nOVERALL SUMMARY\n----------------------------------------------------------------------\n  Total Checks: 28\n  Passed:       28 (100.0%)\n  Failed:       0 (0.0%)\n  Overall Score: 1.00/1.00\n  Decision:      STRONG_PASS\n\n----------------------------------------------------------------------\nCATEGORY BREAKDOWN\n----------------------------------------------------------------------\n  ACCURACY         8/\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.87,
          "evidence": [
            "score=1.0",
            "failed=0",
            "total=28"
          ],
          "message": "Evaluation score meets threshold (computed)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 76899.03,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "Running size_accuracy judge...\n  Score: 5/5 (weight: 35%)\nRunning threshold_quality judge...\n  Score: 5/5 (weight: 25%)\nRunning actionability judge...\n  Score: 4/5 (weight: 20%)\nRunning integration_fit judge...\n  Score: 5/5 (weight: 20%)",
          "stdout_summary": "Running LLM evaluation...\n\n======================================================================\nGIT-SIZER LLM EVALUATION REPORT\n======================================================================\n\nTimestamp: 2026-02-08T09:42:40.232454+00:00\nAnalysis:  /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-iwmjts2u\nModel:     opus-4.5\n\n----------------------------------------------------------------------\nSUMMARY\n----------------------------------------------------------------------\n  Weighted Score: 4.8/5.0\n  Grade:          A\n  Verdict:        STRONG_PASS\n\n----------------------------------------------------------------------\nJUDGE RESULTS\n----------------------------------------------------------------------\n\n  SIZE_ACCURACY (weight: 35%)\n    Score:      5/5 (weighted: 1.7\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.7,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.51,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-iwmjts2u/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.35,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.09,
          "evidence": [
            "violations[0] missing required field: file_path",
            "violations[0] missing required field: rule_id"
          ],
          "message": "Data completeness issues detected",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "git-sizer",
            "git-sizer"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.54,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 244.26,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.33,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.61,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.12,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.58,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.57,
          "evidence": [
            "integration_fit.py",
            "size_accuracy.py",
            "actionability.py",
            "threshold_quality.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 13.75,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: size_accuracy.py",
            "prompt: size_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.38,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_dir",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.1,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.13,
          "evidence": [
            "timestamp",
            "analysis_path",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.11,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.1,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.24,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_git_sizer_repo_level_only.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 4.28,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 212.52,
          "evidence": [
            "Fixture: git_sizer_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.73,
          "evidence": [
            "health_grade_valid",
            "metrics_non_negative",
            "violation_levels"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.63,
          "evidence": [],
          "message": "Adapter GitSizerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.32,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "Tool 'git-sizer' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.55,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql",
            "stg_git_sizer_lfs_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.26,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql",
            "stg_git_sizer_lfs_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 12.97,
          "evidence": [
            "GitSizerMetric",
            "GitSizerViolation",
            "GitSizerLfsCandidate"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.03,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 76.68,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.81,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-sizer",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 31893.75,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-i497279u \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/eval-repos/synthetic\nUsing gitleaks: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/bin/gitleaks\nGit\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 129.72,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis-dir outputs/runs \\\n\t\t--ground-truth-dir evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-9v9grg5g\nGitleaks PoC Evaluation\n============================================================\nNo analysis files found in outputs/runs\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-9v9grg5g/evaluation_report.json"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-9v9grg5g/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-9v9grg5g/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-9v9grg5g/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 64768.72,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--working-dir . \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json \\\n\t\t--model opus-4.5 \\\n\t\t--evaluation-mode synthetic\nLLM Evaluation for poc-gitleaks\nModel: opus-4.5\nWorking directory: .\nEvaluation mode: synthetic\n============================================================\n\nRunning 4 judges...\n\nRunning detection_accuracy evaluation...\n  Score: 1/5 (confidence: 0.99)\nRunning false_positive evaluation...\n  Score: 3/5 (confidence: 0.30)\nRunning secret_coverage evaluation...\n  Score: 1/5 (confidence: 0.95)\nRunning severity_classification evaluation...\n  Score: 1/5 (confidence: 0.95)\n\n============================================================\nRESULTS\n============\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-f0g8_bjp/llm_evaluation.json"
          ],
          "message": "LLM evaluation JSON missing",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.93,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-i497279u/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 2.71,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.29,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.04,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.04,
          "evidence": [
            "gitleaks",
            "gitleaks"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.86,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 161.51,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.33,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.67,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.43,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.59,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.33,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.51,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.9,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.5,
          "evidence": [
            "false_positive.py",
            "secret_coverage.py",
            "detection_accuracy.py",
            "severity_classification.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 5.13,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary",
            "categories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.06,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.29,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.37,
          "evidence": [
            "src/tools/gitleaks/tests/unit/test_rollup_invariants.py",
            "src/sot-engine/dbt/tests/test_rollup_gitleaks_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.39,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 132.37,
          "evidence": [
            "Fixture: gitleaks_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.56,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "Adapter GitleaksAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.27,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Tool 'gitleaks' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.23,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.68,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 9.49,
          "evidence": [
            "GitleaksSecret"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.9,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 63.89,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.5,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "gitleaks",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 301.35,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Setup complete!\nScanning synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-_ux3xyce\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/eval-repos/synthetic\nFiles found: 143\nDirectories: 79\nScan duration: 26ms\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-_ux3xyce/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 284.61,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Setup complete!\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4ox47rag /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate\nEvaluating output.json...\n  Score: 4.75/5.0 - STRONG_PASS\n  Checks: 33/36 passed\n\nResults saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4ox47rag/evaluation_report.json\nScorecard saved to /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-4ox47rag/scorecard.md\n\nAggregate: 4.75/5.0 - STRONG_PASS"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.52,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 201345.91,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Setup complete!\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--working-dir /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-_ux3xyce/output.json \\\n\t\t--model opus-4.5 \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ldi7t5yy/llm_evaluation.json \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json\nRunning full evaluation (4 judges)...\nRunning classification_reasoning evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning directory_taxonomy evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning hierarchy_consistency evaluation...\n  Score: 5/5 (confidence: 0.88)\nRunnin\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.46,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.71,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-_ux3xyce/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 15.2,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "layout-scanner",
            "layout-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.77,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 449.88,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.63,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.28,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.25,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.59,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.96,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.21,
          "evidence": [
            "classification_reasoning.py",
            "hierarchy_consistency.py",
            "language_detection.py",
            "directory_taxonomy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 17.87,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: classification_reasoning.py",
            "prompt: classification_reasoning.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 7.11,
          "evidence": [
            "mixed-language.json",
            "edge-cases.json",
            "generated-code.json",
            "config-heavy.json",
            "vendor-heavy.json",
            "small-clean.json",
            "deep-nesting.json",
            "mixed-types.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 3.61,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "evaluated_count",
            "average_score",
            "summary",
            "checks",
            "repositories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 2.36,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.15,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.39,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.19,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.15,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.78,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_layout_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 6.53,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 377.07,
          "evidence": [
            "Fixture: layout_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.03,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.73,
          "evidence": [],
          "message": "Adapter LayoutAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.37,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.0,
          "evidence": [
            "Layout is ingested before TOOL_INGESTION_CONFIGS loop"
          ],
          "message": "layout-scanner handled specially as prerequisite tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 1.45,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 2.62,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 29.03,
          "evidence": [
            "LayoutFile",
            "LayoutDirectory"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 2.2,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 109.6,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.64,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "layout-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 241.21,
          "evidence": [
            "Running function analysis on synthetic..."
          ],
          "message": "make analyze failed",
          "severity": "critical",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/scripts/analyze.py\", line 13, in <module>\n    from function_analyzer import (\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/scripts/function_analyzer.py\", line 20, in <module>\n    import lizard\nModuleNotFoundError: No module named 'lizard'\nmake[1]: *** [analyze] Error 1",
          "stdout_summary": "Running function analysis on synthetic..."
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 221.29,
          "evidence": [
            "Running programmatic evaluation (76 checks)..."
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/scripts/analyze.py\", line 13, in <module>\n    from function_analyzer import (\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/scripts/function_analyzer.py\", line 20, in <module>\n    import lizard\nModuleNotFoundError: No module named 'lizard'\nmake[1]: *** [evaluate] Error 1",
          "stdout_summary": "Running programmatic evaluation (76 checks)..."
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 55166.11,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "<frozen runpy>:128: RuntimeWarning: 'evaluation.llm.orchestrator' found in sys.modules after import of package 'evaluation.llm', but prior to execution of 'evaluation.llm.orchestrator'; this may result in unpredictable behaviour",
          "stdout_summary": "Running LLM evaluation (4 judges)...\n\n============================================================\nLLM Evaluation - Lizard Function Complexity Analysis\n============================================================\n\nRunning ccn_accuracy evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 2/5 (confidence: 0.45)\nRunning function_detection evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\nRunning statistics evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\nRunning hotspot_ranking evaluation...\n  Ground truth assertions failed: 1 failures\n  Score: 1/5 (confidence: 0.95)\n\n============================================================\nEVALUATION SUMMARY\n==================================================\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.38,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 4.25,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 16.85,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.14,
          "evidence": [
            "Checked 85 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "lizard",
            "lizard"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.91,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 238.9,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.54,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.11,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.63,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.17,
          "evidence": [
            "hotspot_ranking.py",
            "ccn_accuracy.py",
            "function_detection.py",
            "statistics.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 11.67,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: ccn_accuracy.py",
            "prompt: ccn_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.68,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "analysis_path",
            "ground_truth_path",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.36,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.32,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.56,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 148.8,
          "evidence": [
            "Fixture: lizard_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.72,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.62,
          "evidence": [],
          "message": "Adapter LizardAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.3,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "Tool 'lizard' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.26,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.68,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 9.09,
          "evidence": [
            "LizardFileMetric",
            "LizardFunctionMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.74,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 66.83,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.5,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "lizard",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 7774.03,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-t7q_tovz/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 278.02,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation (~28 checks)...\n======================================================================\nPMD CPD EVALUATION REPORT\n======================================================================\n\nAnalysis: outputs/cpd-test-run/output.json\nGround Truth: evaluation/ground-truth\nTimestamp: 2026-02-08T10:50:01.877531\n\n----------------------------------------------------------------------\nSUMMARY\n----------------------------------------------------------------------\nTotal Checks: 28\nPassed: 27\nFailed: 1\nOverall Score: 89.03%\n\nScore by Category:\n  ACCURACY: 76.96% (8/8 passed)\n  COVERAGE: 100.00% (8/8 passed)\n  EDGE_CASES: 97.13% (8/8 passed)\n  PERFORMANCE: 75.00% (3/4 passed)\n\n----------------------------------------------------------------------\nCHECK RESULTS\n-------------\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-aifbhgi7/scorecard.md"
          ],
          "message": "Missing evaluation outputs",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 2.39,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 8642.05,
          "evidence": [
            "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-t7q_tovz/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning LLM evaluation (4 judges)..."
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 348, in <module>\n    main()\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 271, in main\n    report = run_llm_evaluation(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/scripts/llm_evaluate.py\", line 93, in run_llm_evaluation\n    DuplicationAccuracyJudge(\nTypeError: BaseJudge.__init__() got an unexpected keyword argument 'analysis_path'\nmake[1]: *** [evaluate-llm] Error 1",
          "stdout_summary": "Java found: /opt/homebrew/opt/openjdk@17/bin/java\nRunning CPD analysis on synthetic...\nAnalyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/eval-repos/synthetic...\nAnalysis complete: 39 clones found\nOutput written to: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-t7q_tovz/output.json\nWarnings: 1\n  - CPD error for rust: Invalid value for option '--language': Unknown language: rust\nUsage: pmd cpd [-Dh] [--ignore-annotations] [--ignore-identifiers]\n               [--ignore-literal-sequences] [--ignore-literals]\n       \nRunning LLM evaluation (4 judges)..."
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.96,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-t7q_tovz/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.79,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.12,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "pmd-cpd",
            "pmd-cpd"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.8,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 196.85,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.13,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.65,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.8,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.18,
          "evidence": [
            "duplication_accuracy.py",
            "actionability.py",
            "semantic_detection.py",
            "cross_file_detection.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.42,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: duplication_accuracy.py",
            "prompt: duplication_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.42,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.21,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.22,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "combined_score",
            "notes"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=WEAK_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.41,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_pmd_cpd_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 4.73,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 253.95,
          "evidence": [
            "Fixture: pmd_cpd_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.41,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Adapter PmdCpdAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.3,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Tool 'pmd-cpd' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.37,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.78,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 16.07,
          "evidence": [
            "PmdCpdFileMetric",
            "PmdCpdDuplication",
            "PmdCpdOccurrence"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 57.14,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.96,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "pmd-cpd",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 20398.97,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 12616.1,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 3.34,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 99690.45,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Building external repo: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/eval-repos/synthetic...\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nMSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file.\nBuild completed (some errors may be expected)\nRunning Roslyn analysis...\nBuilding AsyncPatterns.csproj...\n  Found 150 violations\nBuilding NullSafety.csproj...\n  Found 83 violations\nBuilding ApiConventions.csproj...\n  Found 1 violations\nBuilding SyntheticSmells.csproj...\n  Found 1051 violations\nBuilding ResourceManagement.csproj...\n  Found 6 violations\n\n=======================================\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.52,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 5.01,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-58u3f_u3/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 35.13,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.11,
          "evidence": [
            "Checked 62 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "roslyn-analyzers",
            "roslyn-analyzers"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.5,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 388.78,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.13,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.37,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 10.29,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 1.15,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.19,
          "evidence": [
            "overall_quality.py",
            "integration_fit.py",
            "resource_management.py",
            "security_detection.py",
            "design_analysis.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 38.16,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.17,
          "evidence": [
            "clean-code.json",
            "resource-management.json",
            "dead-code.json",
            "csharp.json",
            "security-issues.json",
            "design-violations.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.24,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 1.92,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.07,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.2,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.18,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.82,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 2.57,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_roslyn_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.83,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 6.82,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 441.38,
          "evidence": [
            "Fixture: roslyn_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.16,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.93,
          "evidence": [],
          "message": "Adapter RoslynAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.37,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.58,
          "evidence": [],
          "message": "Tool 'roslyn-analyzers' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.33,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 1.37,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 13.09,
          "evidence": [
            "RoslynViolation"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.33,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 219.0,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.72,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "roslyn-analyzers",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 535.31,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running license analysis on synthetic...\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/eval-repos/synthetic\nLicenses found: ['Apache-2.0', 'BSD-3-Clause', 'GPL-2.0-only WITH Classpath-exception-2.0', 'GPL-3.0-only', 'LGPL-2.1-only', 'MIT', 'Unlicense']\nOverall risk: critical\nFiles with licenses: 23\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-c0fvgecw/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 309.98,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running programmatic evaluation...\nLicense Analysis Evaluation\n============================================================\n\nno-license: 32/32 (PASS)\napache-bsd: 32/32 (PASS)\nmit-only: 32/32 (PASS)\napache-bsd: 32/32 (PASS)\ngpl-mixed: 32/32 (PASS)\nmulti-license: 32/32 (PASS)\n\n============================================================\nSummary\n============================================================\nRepositories evaluated: 6\nTotal checks: 192\nPassed: 192\nFailed: 0\nOverall pass rate: 100.0%\n\nScorecard saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.json\nMarkdown scorecard saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.md\n\nResults saved to: evaluation/results/evaluati\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.0,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-owig3o3k/checks.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-owig3o3k/evaluation_report.json",
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-owig3o3k/llm_evaluation.json"
          ],
          "message": "Evaluation results JSON missing",
          "severity": "high",
          "status": "fail",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 14130.87,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running LLM-as-a-Judge evaluation...\nLLM Evaluation for scancode\nModel: opus-4.5\nWorking directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode\n============================================================\n\nRunning 4 judges...\n\nRunning accuracy evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning coverage evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning actionability evaluation...\n  Score: 3/5 (confidence: 0.50)\nRunning risk_classification evaluation...\n  Score: 3/5 (confidence: 0.50)\n\n============================================================\nRESULTS\n============================================================\nTotal Score: 3.00\nDecision: WEAK_PASS\n\nResults saved to: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evalu\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.93,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.51,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-c0fvgecw/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.57,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.05,
          "evidence": [
            "Checked 23 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "scancode",
            "scancode"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.58,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 143.84,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.11,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.5,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.18,
          "evidence": [
            "coverage_judge.py",
            "accuracy_judge.py",
            "actionability_judge.py",
            "risk_classification_judge.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 17.83,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy_judge.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [
            "multi-license.json",
            "mit-only.json",
            "gpl-mixed.json",
            "apache-bsd.json",
            "public-domain.json",
            "spdx-expression.json",
            "no-license.json",
            "dual-licensed.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.77,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "summary",
            "checks",
            "total_repositories",
            "reports"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.53,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.05,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 1.03,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "dimensions",
            "score",
            "total_score",
            "average_confidence",
            "decision",
            "programmatic_score",
            "combined_score"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.73,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.67,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.21,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scancode_repo_level_metrics.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.3,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 149.51,
          "evidence": [
            "Fixture: scancode_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.44,
          "evidence": [
            "paths",
            "confidence",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "Adapter ScancodeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.3,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "Tool 'scancode' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.25,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 9.75,
          "evidence": [
            "ScancodeFileLicense",
            "ScancodeSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 47.57,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.43,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scancode",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 264.77,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running directory analysis on synthetic...\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/eval-repos/synthetic\nUsing scc: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/bin/scc\nFiles found: 63\nTotal files: 63\nTotal lines: 7,666\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-8e53jh9m/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 186.02,
          "evidence": [
            "Running programmatic evaluation..."
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/scripts/evaluate.py\", line 17, in <module>\n    from scripts.analyze import _resolve_commit\nImportError: cannot import name '_resolve_commit' from 'scripts.analyze' (/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/scripts/analyze.py)\nmake[1]: *** [evaluate] Error 1",
          "stdout_summary": "Running programmatic evaluation..."
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 216803.16,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running LLM-as-a-Judge evaluation...\n============================================================\nLLM-as-a-Judge Evaluation\n============================================================\nMode: full\nModel: opus-4.5\nWorking Directory: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc\n============================================================\n\nRegistering all judges (10 dimensions)...\n\nRunning code_quality evaluation...\n  Score: 4/5 (confidence: 0.88)\nRunning integration_fit evaluation...\n  Score: 4/5 (confidence: 0.92)\nRunning documentation evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning edge_cases evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning error_messages evaluation...\n  Score: 4/5 (confidence: 0.82)\nRunning api_design evaluation...\n  Score: 4/5 (confi\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.8,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.42,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-8e53jh9m/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 5.88,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.15,
          "evidence": [
            "Checked 94 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "scc",
            "scc"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.74,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 173.06,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.65,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.84,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.67,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.19,
          "evidence": [
            "error_messages.py",
            "documentation.py",
            "edge_cases.py",
            "directory_analysis.py",
            "integration_fit.py",
            "code_quality.py",
            "risk.py",
            "statistics.py",
            "comparative.py",
            "api_design.py"
          ],
          "message": "LLM judge count meets minimum (10 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 13.87,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: directory_analysis.py",
            "prompt: directory_analysis.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.23,
          "evidence": [
            "run_id",
            "timestamp",
            "dimensions",
            "total_score",
            "decision"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.19,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.17,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.13,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.11,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.38,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.43,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 154.74,
          "evidence": [
            "Fixture: scc_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.49,
          "evidence": [
            "paths",
            "ranges",
            "ratios",
            "required_fields"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.79,
          "evidence": [],
          "message": "Adapter SccAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.29,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.48,
          "evidence": [],
          "message": "Tool 'scc' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.27,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.73,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 9.84,
          "evidence": [
            "SccFileMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.72,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 61.88,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.48,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scc",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 8158.82,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hcjan9wi\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\nFiles analyzed: 58\nSmells found: 193\nDuration: 6011m\u2026"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 410.18,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nRunning programmatic evaluation (~28 checks)...\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-zfomcb32 /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hcjan9wi/output.json \\\n\t\t--ground-truth evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-zfomcb32/evaluation_report.json\n\n\u001b[36m======================================================================\u001b[0m\n\u001b[36m\u001b[1m  SEMGREP EVALUATION REPORT\u001b[0m\n\u001b[36m====================\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.25,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 127442.07,
          "evidence": [],
          "message": "make evaluate-llm succeeded",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": "[DEBUG] Looking for analysis files in: outputs\n  [DEBUG] Found 16 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Looking for analysis files in: outputs\n  [DEBUG] Found 16 JSON files\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Loaded: output.json\n  [DEBUG] Load\u2026",
          "stdout_summary": "SKIP_SETUP=1: skipping semgrep install\nInitializing real repositories...\nInitializing Elttam audit rules...\n  Elttam rules already present\nSetup complete!\nAnalyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\" \\\n\t\t--repo-name \"synthetic\" \\\n\t\t--output-dir \"/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hcjan9wi\" \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\"\nAnalyzing: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/eval-repos/synthetic\nFiles analyzed: 58\nSmells found: 193\nDuration: 5704m\u2026"
        },
        {
          "check_id": "evaluation.llm_results",
          "duration_ms": null,
          "evidence": [],
          "message": "LLM evaluation output present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.76,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.21,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-hcjan9wi/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 7.14,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.12,
          "evidence": [
            "Checked 65 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "semgrep",
            "semgrep"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 2.88,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 222.9,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.02,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.15,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.81,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.93,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.21,
          "evidence": [
            "rule_coverage.py",
            "actionability.py",
            "security_detection.py",
            "smell_accuracy.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 20.4,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.14,
          "evidence": [
            "java.json",
            "go.json",
            "csharp.json",
            "rust.json",
            "javascript.json",
            "typescript.json",
            "python.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.25,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.17,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "analysis_path",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.18,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.12,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.4,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_semgrep_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.67,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 175.15,
          "evidence": [
            "Fixture: semgrep_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 2.21,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.91,
          "evidence": [],
          "message": "Adapter SemgrepAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.34,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.6,
          "evidence": [],
          "message": "Tool 'semgrep' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.28,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.88,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 10.44,
          "evidence": [
            "SemgrepSmell"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.15,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 65.16,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.5,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "semgrep",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 214.78,
          "evidence": [
            "Analyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/eval-repos/synthetic \\\n\t\t--project-key synthetic \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--sonarqube-url http://localhost:9000 \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\" \\\n\t\t \\\n\t\t \\"
          ],
          "message": "make analyze failed",
          "severity": "critical",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/scripts/analyze.py\", line 18, in <module>\n    import structlog\nModuleNotFoundError: No module named 'structlog'\nmake[1]: *** [analyze] Error 1",
          "stdout_summary": "Analyzing synthetic...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/eval-repos/synthetic \\\n\t\t--project-key synthetic \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--sonarqube-url http://localhost:9000 \\\n\t\t--run-id \"compliance\" \\\n\t\t--repo-id \"compliance\" \\\n\t\t--branch \"main\" \\\n\t\t--commit \"2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2\" \\\n\t\t \\\n\t\t \\"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 116.58,
          "evidence": [
            "Running programmatic evaluation...\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-mq8hb07h /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--ground-truth evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-mq8hb07h/evaluation_report.json"
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "Error: Analysis file not found: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json\nmake[1]: *** [evaluate] Error 1",
          "stdout_summary": "Running programmatic evaluation...\nEVAL_OUTPUT_DIR=/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-mq8hb07h /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--ground-truth evaluation/ground-truth \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-mq8hb07h/evaluation_report.json"
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 168.03,
          "evidence": [
            "Running LLM evaluation (3 judges)...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.llm_evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-n2cxpbme/llm_evaluation.json \\\n\t\t--model opus-4.5 \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json"
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "Error: Analysis file not found: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json\nmake[1]: *** [evaluate-llm] Error 1",
          "stdout_summary": "Running LLM evaluation (3 judges)...\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.llm_evaluate \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-fy9i5v94/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-n2cxpbme/llm_evaluation.json \\\n\t\t--model opus-4.5 \\\n\t\t--programmatic-results evaluation/results/evaluation_report.json"
        },
        {
          "check_id": "output.load",
          "duration_ms": 4.23,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/outputs/B6FAEEC8-1FC9-47A2-BD1D-9B3329C3E4C4/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 7.03,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.2.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "sonarqube",
            "sonarqube"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.62,
          "evidence": [
            "1.2.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 204.45,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.14,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.76,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.91,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.29,
          "evidence": [
            "issue_accuracy.py",
            "integration_fit.py",
            "actionability.py",
            "coverage_completeness.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 11.76,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: issue_accuracy.py",
            "prompt: issue_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.14,
          "evidence": [
            "java-security.json",
            "typescript-duplication.json",
            "csharp-baseline.json",
            "python-mixed.json",
            "csharp-complex.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.25,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.09,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.39,
          "evidence": [
            "timestamp",
            "analysis_path",
            "summary",
            "dimensions",
            "model",
            "score",
            "decision",
            "programmatic_input",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.42,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_sonarqube_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.39,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 304.46,
          "evidence": [
            "Fixture: sonarqube_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.98,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Adapter SonarqubeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.34,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Tool 'sonarqube' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.29,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.96,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 14.32,
          "evidence": [
            "SonarqubeIssue",
            "SonarqubeMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.62,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 26.69,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.66,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "sonarqube",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 1562.98,
          "evidence": [],
          "message": "make analyze succeeded",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": "",
          "stdout_summary": "Running symbol extraction on synthetic...\nSymbol Scanner v0.1.0\n\nAnalyzing synthetic...\nRepository: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic\n\nFiles analyzed: 25\nSymbols found: 609\n  - Functions: 200\n  - Classes: 110\n  - Methods: 286\n  - Variables: 13\nCalls found: 615\n  - Direct: 306\n  - Dynamic: 284\n  - Async: 25\n  - Resolved: 137\n    - Same file: 137\n    - Cross file: 0\n  - Unresolved: 478\nImports found: 63\n  - Static: 58\n  - Dynamic: 0\nErrors: 1\n\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-0awr5y9j/output.json"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 2386.82,
          "evidence": [],
          "message": "make evaluate succeeded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": "Warning: Repository csharp-tshock not found at /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic/csharp-tshock\n  Minor regression: 99.77% -> 99.07% (within threshold)",
          "stdout_summary": "Running programmatic evaluation...\nSymbol Scanner v0.1.0\n\nAnalyzing synthetic...\nRepository: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/synthetic\n\nFiles analyzed: 25\nSymbols found: 609\n  - Functions: 200\n  - Classes: 110\n  - Methods: 286\n  - Variables: 13\nCalls found: 615\n  - Direct: 306\n  - Dynamic: 284\n  - Async: 25\n  - Resolved: 137\n    - Same file: 137\n    - Cross file: 0\n  - Unresolved: 478\nImports found: 63\n  - Static: 58\n  - Dynamic: 0\nErrors: 1\n\nOutput: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-x9f1tleh/output.json\nRunning evaluation in analysis mode...\nGround truth: evaluation/ground-truth\nRepos dir: /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/eval-repos/syntheti\u2026"
        },
        {
          "check_id": "evaluation.results",
          "duration_ms": null,
          "evidence": [],
          "message": "Evaluation outputs present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.76,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 178.95,
          "evidence": [
            "Running LLM evaluation (4 judges)..."
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "usage: orchestrator.py [-h] [--analysis ANALYSIS] [--output OUTPUT]\n                       [--model MODEL]\n                       [--programmatic-results PROGRAMMATIC_RESULTS]\n                       [--focused]\norchestrator.py: error: unrecognized arguments: --working-dir .\nmake[1]: *** [evaluate-llm] Error 2",
          "stdout_summary": "Running LLM evaluation (4 judges)..."
        },
        {
          "check_id": "output.load",
          "duration_ms": 4.47,
          "evidence": [
            "/var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-x9f1tleh/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 27.64,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "symbol-scanner",
            "symbol-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.82,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 217.79,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.65,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.84,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.17,
          "evidence": [
            "call_relationship.py",
            "import_completeness.py",
            "integration.py",
            "symbol_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.6,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: call_relationship.py",
            "prompt: call_relationship.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.16,
          "evidence": [
            "metaprogramming.json",
            "csharp-tshock.json",
            "cross-module-calls.json",
            "deep-hierarchy.json",
            "encoding-edge-cases.json",
            "circular-imports.json",
            "type-checking-imports.json",
            "decorators-advanced.json",
            "dynamic-code-generation.json",
            "async-patterns.json",
            "nested-structures.json",
            "class-hierarchy.json",
            "simple-functions.json",
            "generators-comprehensions.json",
            "dataclasses-protocols.json",
            "deep-nesting-stress.json",
            "partial-syntax-errors.json",
            "unresolved-externals.json",
            "confusing-names.json",
            "modern-syntax.json",
            "large-file.json",
            "web-framework-patterns.json",
            "import-patterns.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.8,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "checks",
            "summary",
            "aggregate",
            "per_repo_results",
            "metadata",
            "regression"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.44,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.23,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.27,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.1,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.29,
          "evidence": [
            "src/sot-engine/dbt/models/staging/stg_lz_code_symbols.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.27,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 182.19,
          "evidence": [
            "Fixture: symbol_scanner_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.74,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Adapter SymbolScannerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.3,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Tool 'symbol-scanner' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.28,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.26,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 10.39,
          "evidence": [
            "CodeSymbol",
            "SymbolCall",
            "FileImport"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 2.04,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 25.03,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.4,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "symbol-scanner",
      "status": "fail"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 147.09,
          "evidence": [
            "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-88dnw6w6 \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2 \\\n\t\t--timeout 600"
          ],
          "message": "make analyze failed",
          "severity": "critical",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/scripts/analyze.py\", line 15, in <module>\n    import structlog\nModuleNotFoundError: No module named 'structlog'\nmake[1]: *** [analyze] Error 1",
          "stdout_summary": "Analyzing /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic as project 'synthetic'\n/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m scripts.analyze \\\n\t\t--repo-path /Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/eval-repos/synthetic \\\n\t\t--repo-name synthetic \\\n\t\t--output-dir /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-88dnw6w6 \\\n\t\t--run-id compliance \\\n\t\t--repo-id compliance \\\n\t\t--branch main \\\n\t\t--commit 2f5bef575d66bab89d7bcb1221ac9bf0ab6b89d2 \\\n\t\t--timeout 600"
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 94.39,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python scripts/evaluate.py --output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ti8fezea/"
          ],
          "message": "make evaluate failed",
          "severity": "high",
          "status": "fail",
          "stderr_summary": "Traceback (most recent call last):\n  File \"/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/scripts/evaluate.py\", line 14, in <module>\n    import structlog\nModuleNotFoundError: No module named 'structlog'\nmake[1]: *** [evaluate] Error 1",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python scripts/evaluate.py --output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-ti8fezea/"
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 105.11,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-88dnw6w6/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-6ez8gcu_/llm_evaluation.json"
          ],
          "message": "make evaluate-llm failed",
          "severity": "medium",
          "status": "fail",
          "stderr_summary": "Error: Analysis file does not exist: /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-88dnw6w6/output.json\nmake[1]: *** [evaluate-llm] Error 1",
          "stdout_summary": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/.venv/bin/python -m evaluation.llm.orchestrator \\\n\t\t--analysis /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-88dnw6w6/output.json \\\n\t\t--output /var/folders/zr/c7zp4x316wvg0rsvdnq_dcm40000gn/T/tool-compliance-eval-6ez8gcu_/llm_evaluation.json"
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.55,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/outputs/f23f9a48-fb85-4c81-8e04-da14641d23b3/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "trivy",
            "trivy"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.61,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 133.46,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.18,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.57,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.14,
          "evidence": [
            "freshness_quality.py",
            "vulnerability_detection.py",
            "vulnerability_accuracy.py",
            "severity_accuracy.py",
            "iac_quality.py",
            "sbom_completeness.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 14.73,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: vulnerability_accuracy.py",
            "prompt: vulnerability_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.13,
          "evidence": [
            "dotnet-outdated.json",
            "js-fullstack.json",
            "vulnerable-npm.json",
            "iac-terraform.json",
            "no-vulnerabilities.json",
            "iac-misconfigs.json",
            "mixed-severity.json",
            "java-outdated.json",
            "critical-cves.json",
            "outdated-deps.json",
            "cfn-misconfigs.json",
            "k8s-misconfigs.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.67,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "classification",
            "overall_score",
            "summary",
            "checks",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.26,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.43,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.11,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.09,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.26,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_trivy_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.42,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 270.04,
          "evidence": [
            "Fixture: trivy_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.53,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Adapter TrivyAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.31,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Tool 'trivy' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.27,
          "evidence": [
            "stg_trivy_file_metrics.sql",
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.69,
          "evidence": [
            "stg_trivy_file_metrics.sql",
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 9.0,
          "evidence": [
            "TrivyVulnerability",
            "TrivyTarget",
            "TrivyIacMisconfig"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.03,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 22.97,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (203 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.55,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "trivy",
      "status": "fail"
    }
  ],
  "tools_root": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools"
}