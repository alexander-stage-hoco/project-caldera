{
  "generated_at": "2026-02-13T19:29:46.941017+00:00",
  "summary": {
    "failed": 0,
    "passed": 18,
    "tool_count": 18
  },
  "tools": [
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/coverage-ingest/outputs/77D267E0-83B0-41FB-B5B1-E15DAC907D5A/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/coverage-ingest/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.32,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/coverage-ingest/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.43,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.26,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/coverage-ingest/outputs/77D267E0-83B0-41FB-B5B1-E15DAC907D5A/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.17,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "coverage-ingest",
            "coverage-ingest"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.33,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 156.56,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.12,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.18,
          "evidence": [
            "cross_format_consistency.py",
            "gap_actionability.py",
            "parser_accuracy.py",
            "risk_tier_quality.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 10.09,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: gap_actionability.py",
            "prompt: gap_actionability.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.06,
          "evidence": [
            "timestamp",
            "score",
            "decision",
            "summary",
            "passed",
            "total",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.09,
          "evidence": [
            "timestamp",
            "output_dir",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.25,
          "evidence": [
            "src/tools/coverage-ingest/tests/unit/test_lcov_parser.py",
            "src/tools/coverage-ingest/tests/unit/test_jacoco_parser.py",
            "src/tools/coverage-ingest/tests/integration/test_e2e.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 144.26,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.08,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 48.78,
          "evidence": [
            "Fixture: coverage_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.75,
          "evidence": [
            "paths",
            "ranges",
            "coverage_invariants",
            "required_fields"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Adapter CoverageAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Tool 'coverage-ingest' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.18,
          "evidence": [
            "stg_lz_coverage_summary.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_coverage_summary.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.22,
          "evidence": [
            "CoverageSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.81,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 49.2,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.33,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "coverage-ingest",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/outputs/97020773-FE31-4C93-A4A0-EE1CA481ACD0/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.29,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.22,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.2,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/outputs/97020773-FE31-4C93-A4A0-EE1CA481ACD0/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "dependensee",
            "dependensee"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.23,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 108.52,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.91,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.06,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.16,
          "evidence": [
            "input: $(LATEST_OUTPUT)"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.66,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.41,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.09,
          "evidence": [
            "project_detection.py",
            "circular_detection.py",
            "graph_quality.py",
            "dependency_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.63,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: dependency_accuracy.py",
            "prompt: dependency_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.1,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.07,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dependensee/evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.19,
          "evidence": [
            "src/tools/dependensee/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.79,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 41.66,
          "evidence": [
            "Fixture: dependensee_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.49,
          "evidence": [
            "paths",
            "required_fields"
          ],
          "message": "All 2 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Adapter DependenseeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'dependensee' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_dependensee_package_refs.sql",
            "stg_dependensee_projects.sql",
            "stg_dependensee_project_refs.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.16,
          "evidence": [
            "stg_dependensee_package_refs.sql",
            "stg_dependensee_projects.sql",
            "stg_dependensee_project_refs.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.66,
          "evidence": [
            "DependenseeProject",
            "DependenseeProjectReference",
            "DependenseePackageReference"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.35,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.29,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dependensee",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.26,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/llm/results/llm-eval-20260213-192743.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.21,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.5,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.48,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.04,
          "evidence": [
            "Checked 31 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "devskim",
            "devskim"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.38,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 129.4,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.35,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.38,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "rule_coverage.py",
            "severity_calibration.py",
            "security_focus.py",
            "detection_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 6.89,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [
            "api-security.json",
            "deserialization.json",
            "xxe.json",
            "csharp.json",
            "clean.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.11,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.24,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "score",
            "decision",
            "dimensions",
            "total_score",
            "average_confidence",
            "combined_score",
            "programmatic_input"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/devskim/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.25,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_devskim_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.77,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 50.2,
          "evidence": [
            "Fixture: devskim_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.38,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Adapter DevskimAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Tool 'devskim' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.5,
          "evidence": [
            "stg_lz_devskim_findings.sql",
            "stg_devskim_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.49,
          "evidence": [
            "DevskimFinding"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.36,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 1.12,
          "evidence": [
            "coverage=80.7%",
            "threshold=80%"
          ],
          "message": "Test coverage 80.7% >= 80% threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "devskim",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.29,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.26,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.24,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/dotcover/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "dotcover",
            "dotcover"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.29,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 108.54,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.37,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.08,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.06,
          "evidence": [
            "input: $(SYNTHETIC_OUTPUT_DIR)"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.17,
          "evidence": [
            "false_positive.py",
            "actionability.py",
            "integration.py",
            "accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 8.42,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.05,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.19,
          "evidence": [
            "src/tools/dotcover/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.0,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 82.77,
          "evidence": [
            "Fixture: dotcover_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.6,
          "evidence": [
            "coverage_bounds",
            "statement_invariants",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Adapter DotcoverAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Tool 'dotcover' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.19,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.15,
          "evidence": [
            "stg_dotcover_file_metrics.sql",
            "stg_lz_dotcover_type_coverage.sql",
            "stg_lz_dotcover_method_coverage.sql",
            "stg_lz_dotcover_assembly_coverage.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.01,
          "evidence": [
            "DotcoverAssemblyCoverage",
            "DotcoverTypeCoverage",
            "DotcoverMethodCoverage"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.48,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.3,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "dotcover",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-blame-scanner/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-blame-scanner/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.27,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-blame-scanner/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.34,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 16.56,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-blame-scanner/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 219.18,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 1.07,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 13.01,
          "evidence": [
            "Checked 11828 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.02,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.02,
          "evidence": [
            "git-blame-scanner",
            "git-blame-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.48,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 716.06,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.34,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.21,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.08,
          "evidence": [
            "input: evaluation/results"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "ownership_accuracy.py",
            "actionability.py",
            "integration.py",
            "churn_validity.py",
            "utils.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 12.52,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: ownership_accuracy.py",
            "prompt: ownership_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.04,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.16,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.14,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.14,
          "evidence": [
            "timestamp",
            "output_dir",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.13,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-blame-scanner/evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.11,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.23,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_git_blame_direct_vs_recursive.sql",
            "src/tools/git-blame-scanner/tests/unit/test_analyze.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.65,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 85.02,
          "evidence": [
            "Fixture: git_blame_scanner_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.87,
          "evidence": [
            "paths",
            "ownership_valid",
            "churn_monotonic",
            "authors_positive"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.63,
          "evidence": [],
          "message": "Adapter GitBlameScannerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.46,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Tool 'git-blame-scanner' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.24,
          "evidence": [
            "stg_git_blame_author_stats.sql",
            "stg_git_blame_summary.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 2.44,
          "evidence": [
            "stg_git_blame_author_stats.sql",
            "stg_git_blame_summary.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.82,
          "evidence": [
            "GitBlameFileSummary",
            "GitBlameAuthorStats"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.82,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 26.75,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.28,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-blame-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.37,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.32,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.28,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "git-fame",
            "git-fame"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.29,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 146.52,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.26,
          "evidence": [
            "integration_readiness.py",
            "concentration_metrics.py",
            "evidence_quality.py",
            "authorship_quality.py",
            "utils.py",
            "bus_factor_accuracy.py",
            "output_completeness.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 15.3,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: authorship_quality.py",
            "prompt: authorship_quality.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.1,
          "evidence": [
            "synthetic.json",
            "multi-author.json",
            "bus-factor-1.json",
            "balanced.json",
            "multi-branch.json",
            "single-author.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.07,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "overall_score",
            "classification",
            "summary",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.11,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-fame/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.29,
          "evidence": [
            "src/tools/git-fame/tests/scripts/test_analyze.py",
            "src/tools/git-fame/tests/scripts/test_authorship_accuracy_checks.py",
            "src/tools/git-fame/tests/scripts/test_output_quality_checks.py",
            "src/tools/git-fame/tests/scripts/test_reliability_checks.py"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.08,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 62.52,
          "evidence": [
            "Fixture: git_fame_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.86,
          "evidence": [
            "hhi_valid",
            "ownership_sums_100",
            "bus_factor_valid"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Adapter GitFameAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'git-fame' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_git_fame_authors.sql",
            "stg_lz_git_fame_summary.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_git_fame_authors.sql",
            "stg_lz_git_fame_summary.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.84,
          "evidence": [
            "GitFameAuthor",
            "GitFameSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.18,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 22.53,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.47,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-fame",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.35,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.17,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.24,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/git-sizer/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "git-sizer",
            "git-sizer"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.19,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 105.41,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 1.32,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.08,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.07,
          "evidence": [
            "input: evaluation/results"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.29,
          "evidence": [
            "integration_fit.py",
            "size_accuracy.py",
            "actionability.py",
            "threshold_quality.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 8.19,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: size_accuracy.py",
            "prompt: size_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.32,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.31,
          "evidence": [
            "timestamp",
            "analysis_path",
            "model",
            "trace_id",
            "judges",
            "summary",
            "programmatic_input",
            "decision",
            "score",
            "dimensions"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.08,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.07,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.18,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_git_sizer_repo_level_only.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.86,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 64.21,
          "evidence": [
            "Fixture: git_sizer_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.46,
          "evidence": [
            "health_grade_valid",
            "metrics_non_negative",
            "violation_levels"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Adapter GitSizerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Tool 'git-sizer' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql",
            "stg_git_sizer_lfs_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.16,
          "evidence": [
            "stg_lz_git_sizer_metrics.sql",
            "stg_lz_git_sizer_violations.sql",
            "stg_lz_git_sizer_lfs_candidates.sql",
            "stg_git_sizer_lfs_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.16,
          "evidence": [
            "GitSizerMetric",
            "GitSizerViolation",
            "GitSizerLfsCandidate"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.96,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.61,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.68,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "git-sizer",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.16,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/evaluation/llm/results/llm-eval-20260213-192252.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.22,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 2.22,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/gitleaks/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 22.35,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.52,
          "evidence": [
            "Checked 614 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "gitleaks",
            "gitleaks"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.62,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 144.37,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.31,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.7,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.45,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.34,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.19,
          "evidence": [
            "input: outputs/runs"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.21,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.99,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "false_positive.py",
            "secret_coverage.py",
            "detection_accuracy.py",
            "severity_classification.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 4.1,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: detection_accuracy.py",
            "prompt: detection_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.48,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary",
            "categories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.07,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.17,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.04,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.44,
          "evidence": [
            "src/tools/gitleaks/tests/unit/test_rollup_invariants.py",
            "src/sot-engine/dbt/tests/test_rollup_gitleaks_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.92,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 82.61,
          "evidence": [
            "Fixture: gitleaks_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.66,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Adapter GitleaksAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Tool 'gitleaks' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.18,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.55,
          "evidence": [
            "stg_gitleaks_secrets.sql",
            "stg_lz_gitleaks_secrets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.28,
          "evidence": [
            "GitleaksSecret"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.71,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 19.33,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.41,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "gitleaks",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 2.27,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.22,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 95.12,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/layout-scanner/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 766.62,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "layout-scanner",
            "layout-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 1.08,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 8842.68,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.71,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.58,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.62,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.43,
          "evidence": [
            "classification_reasoning.py",
            "hierarchy_consistency.py",
            "language_detection.py",
            "directory_taxonomy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 11.59,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: classification_reasoning.py",
            "prompt: classification_reasoning.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.11,
          "evidence": [
            "mixed-language.json",
            "edge-cases.json",
            "generated-code.json",
            "config-heavy.json",
            "vendor-heavy.json",
            "small-clean.json",
            "deep-nesting.json",
            "mixed-types.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 18.61,
          "evidence": [
            "timestamp",
            "evaluated_count",
            "average_score",
            "decision",
            "score",
            "summary",
            "checks",
            "repositories"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 1.5,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.4,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "WEAK_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.26,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_layout_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.89,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 153.9,
          "evidence": [
            "Fixture: layout_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.65,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.55,
          "evidence": [],
          "message": "Adapter LayoutAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.25,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.0,
          "evidence": [
            "Layout is ingested before TOOL_INGESTION_CONFIGS loop"
          ],
          "message": "layout-scanner handled specially as prerequisite tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.87,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 1.25,
          "evidence": [
            "stg_lz_layout_files.sql",
            "stg_lz_layout_directories.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.87,
          "evidence": [
            "LayoutFile",
            "LayoutDirectory"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.97,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 59.77,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.36,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "layout-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/scorecard.md",
            "WARNING: Output is 19 days old (threshold: 14 days)"
          ],
          "message": "Pre-existing evaluation output found (stale)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 1.19,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.29,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.94,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/lizard/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 10.96,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 85 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "lizard",
            "lizard"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.45,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 205.5,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.93,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.07,
          "evidence": [
            "input: $(EVAL_OUTPUT_DIR)/output.json"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.3,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.81,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "hotspot_ranking.py",
            "ccn_accuracy.py",
            "function_detection.py",
            "statistics.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.52,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: ccn_accuracy.py",
            "prompt: ccn_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.34,
          "evidence": [
            "decision",
            "score",
            "timestamp",
            "analysis_path",
            "ground_truth_path",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.28,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.12,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.31,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_lizard_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.31,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 120.99,
          "evidence": [
            "Fixture: lizard_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.55,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "Adapter LizardAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.61,
          "evidence": [],
          "message": "Tool 'lizard' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.21,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.54,
          "evidence": [
            "stg_lz_lizard_file_metrics.sql",
            "stg_lz_lizard_function_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.66,
          "evidence": [
            "LizardFileMetric",
            "LizardFunctionMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.03,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 21.96,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.4,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "lizard",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/outputs/8863DD6A-21EB-424C-AA64-62125959C12C/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.37,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.21,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.39,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/pmd-cpd/outputs/8863DD6A-21EB-424C-AA64-62125959C12C/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 1.48,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.05,
          "evidence": [
            "Checked 49 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "pmd-cpd",
            "pmd-cpd"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.25,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 125.93,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.07,
          "evidence": [
            "input: $(SYNTHETIC_OUTPUT)"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.49,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.09,
          "evidence": [
            "duplication_accuracy.py",
            "actionability.py",
            "semantic_detection.py",
            "cross_file_detection.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 3.99,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: duplication_accuracy.py",
            "prompt: duplication_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Ground truth covers synthetic repos",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.15,
          "evidence": [
            "timestamp",
            "analysis_path",
            "ground_truth_dir",
            "decision",
            "score",
            "summary",
            "checks"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.13,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.06,
          "evidence": [
            "timestamp",
            "analysis_path",
            "model",
            "summary",
            "judges",
            "score",
            "decision",
            "programmatic_input",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.05,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.25,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_pmd_cpd_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.82,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 161.45,
          "evidence": [
            "Fixture: pmd_cpd_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.65,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Adapter PmdCpdAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Tool 'pmd-cpd' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.2,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.7,
          "evidence": [
            "stg_lz_pmd_cpd_duplications.sql",
            "stg_lz_pmd_cpd_occurrences.sql",
            "stg_lz_pmd_cpd_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 8.99,
          "evidence": [
            "PmdCpdFileMetric",
            "PmdCpdDuplication",
            "PmdCpdOccurrence"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.31,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 19.92,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.38,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "pmd-cpd",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/outputs/fb013034-c6dc-4a1a-875f-7a27e86caae6/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.5,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/evaluation/llm/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.31,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.7,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/roslyn-analyzers/outputs/fb013034-c6dc-4a1a-875f-7a27e86caae6/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 17.89,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 71 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "roslyn-analyzers",
            "roslyn-analyzers"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.48,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 143.51,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.09,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.36,
          "evidence": [
            "prerequisites: $(VENV_READY) analyze"
          ],
          "message": "evaluate uses $(OUTPUT_DIR) but depends on analyze",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.55,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.67,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.12,
          "evidence": [
            "overall_quality.py",
            "integration_fit.py",
            "resource_management.py",
            "security_detection.py",
            "design_analysis.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 10.33,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.18,
          "evidence": [
            "clean-code.json",
            "resource-management.json",
            "dead-code.json",
            "csharp.json",
            "security-issues.json",
            "design-violations.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.05,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.04,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.21,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.06,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.31,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_roslyn_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.89,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 114.02,
          "evidence": [
            "Fixture: roslyn_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.53,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Adapter RoslynAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.24,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'roslyn-analyzers' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.23,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 1.2,
          "evidence": [
            "stg_lz_roslyn_violations.sql",
            "stg_roslyn_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 12.9,
          "evidence": [
            "RoslynViolation"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.94,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 19.84,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.74,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "roslyn-analyzers",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.64,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/evaluation/llm/results/llm-eval-20260213-120324.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.6,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.13,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scancode/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 9.3,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.2,
          "evidence": [
            "Checked 197 paths across 1 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "scancode",
            "scancode"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.42,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 139.73,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.47,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.07,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.46,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.42,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.1,
          "evidence": [
            "coverage_judge.py",
            "accuracy_judge.py",
            "actionability_judge.py",
            "risk_classification_judge.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 2.86,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: accuracy_judge.py",
            "prompt: accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.08,
          "evidence": [
            "multi-license.json",
            "mit-only.json",
            "gpl-mixed.json",
            "apache-bsd.json",
            "public-domain.json",
            "spdx-expression.json",
            "no-license.json",
            "dual-licensed.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.42,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "summary",
            "checks",
            "total_repositories",
            "reports"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.41,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 1.45,
          "evidence": [
            "run_id",
            "timestamp",
            "model",
            "dimensions",
            "score",
            "total_score",
            "average_confidence",
            "decision",
            "programmatic_score",
            "combined_score"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.86,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.7,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.24,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scancode_repo_level_metrics.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.12,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 105.04,
          "evidence": [
            "Fixture: scancode_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.5,
          "evidence": [
            "paths",
            "confidence",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.24,
          "evidence": [],
          "message": "Adapter ScancodeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.22,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.18,
          "evidence": [],
          "message": "Tool 'scancode' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.17,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.15,
          "evidence": [
            "stg_lz_scancode_summary.sql",
            "stg_lz_scancode_file_licenses.sql",
            "stg_scancode_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.99,
          "evidence": [
            "ScancodeFileLicense",
            "ScancodeSummary"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.7,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.56,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.42,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scancode",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/scorecard.md",
            "WARNING: Output is 19 days old (threshold: 14 days)"
          ],
          "message": "Pre-existing evaluation output found (stale)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.36,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/llm/results/llm-eval-20260125-104034.json",
            "WARNING: Output is 19 days old (threshold: 14 days)"
          ],
          "message": "Pre-existing LLM evaluation output found (stale)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.24,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.76,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/scc/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 4.72,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.09,
          "evidence": [
            "Checked 94 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "scc",
            "scc"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.0,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.36,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 203.79,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.84,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.9,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.4,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.21,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.12,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 1.36,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 1.01,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.35,
          "evidence": [
            "error_messages.py",
            "documentation.py",
            "edge_cases.py",
            "directory_analysis.py",
            "integration_fit.py",
            "code_quality.py",
            "risk.py",
            "statistics.py",
            "comparative.py",
            "api_design.py"
          ],
          "message": "LLM judge count meets minimum (10 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 55.62,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: directory_analysis.py",
            "prompt: directory_analysis.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "synthetic.json ground truth present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.46,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary",
            "run_id",
            "dimensions",
            "total_score"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.99,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.35,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 1.58,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.65,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 1.31,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 2.08,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_distribution_ranges.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_direct_vs_recursive.sql",
            "src/sot-engine/dbt/tests/test_rollup_scc_distribution_ranges.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.64,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 4.85,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 182.03,
          "evidence": [
            "Fixture: scc_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.48,
          "evidence": [
            "paths",
            "ranges",
            "ratios",
            "required_fields"
          ],
          "message": "All 4 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.28,
          "evidence": [],
          "message": "Adapter SccAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.27,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Tool 'scc' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.24,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.54,
          "evidence": [
            "stg_lz_scc_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 7.74,
          "evidence": [
            "SccFileMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.36,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 21.43,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.5,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "scc",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.21,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/llm/results/llm-eval-20260130-120000.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.18,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.67,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 5.57,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.07,
          "evidence": [
            "Checked 65 paths across 2 sections"
          ],
          "message": "Path consistency validated",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "semgrep",
            "semgrep"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.31,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 128.83,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.52,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "analyze target output pattern acceptable",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.08,
          "evidence": [
            "input: evaluation/results/output.json"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.65,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.62,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.09,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.31,
          "evidence": [
            "rule_coverage.py",
            "actionability.py",
            "security_detection.py",
            "smell_accuracy.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (5 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 13.58,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: security_detection.py",
            "prompt: security_detection.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.09,
          "evidence": [
            "java.json",
            "go.json",
            "csharp.json",
            "rust.json",
            "javascript.json",
            "typescript.json",
            "python.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.06,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.15,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.27,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "analysis_path",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.09,
          "evidence": [
            "file=/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/semgrep/evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.08,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.27,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_semgrep_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.04,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 1.74,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 104.69,
          "evidence": [
            "Fixture: semgrep_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.46,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.26,
          "evidence": [],
          "message": "Adapter SemgrepAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.19,
          "evidence": [],
          "message": "Tool 'semgrep' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.17,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.56,
          "evidence": [
            "stg_semgrep_file_metrics.sql",
            "stg_lz_semgrep_smells.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 6.92,
          "evidence": [
            "SemgrepSmell"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.98,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 18.14,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.45,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "semgrep",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.19,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/llm/results/llm-eval-20260130-120000.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.18,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.51,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/sonarqube/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 4.45,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.2.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "sonarqube",
            "sonarqube"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.42,
          "evidence": [
            "1.2.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 111.67,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "analyze target produces output.json",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.08,
          "evidence": [
            "input: evaluation/results/output.json"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.54,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.51,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.35,
          "evidence": [
            "issue_accuracy.py",
            "integration_fit.py",
            "actionability.py",
            "coverage_completeness.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 7.35,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: issue_accuracy.py",
            "prompt: issue_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.18,
          "evidence": [
            "java-security.json",
            "typescript-duplication.json",
            "csharp-baseline.json",
            "python-mixed.json",
            "csharp-complex.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.01,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.05,
          "evidence": [
            "timestamp",
            "tool",
            "decision",
            "score",
            "checks",
            "summary"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.04,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.03,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.15,
          "evidence": [
            "timestamp",
            "analysis_path",
            "summary",
            "dimensions",
            "model",
            "score",
            "decision",
            "programmatic_input",
            "combined"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.04,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.04,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.32,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_sonarqube_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.01,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 183.88,
          "evidence": [
            "Fixture: sonarqube_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 0.65,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.29,
          "evidence": [],
          "message": "Adapter SonarqubeAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.23,
          "evidence": [
            "Found 2 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Tool 'sonarqube' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.23,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.79,
          "evidence": [
            "stg_sonarqube_issues.sql",
            "stg_sonarqube_file_metrics.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 10.4,
          "evidence": [
            "SonarqubeIssue",
            "SonarqubeMetric"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.53,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 19.21,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.26,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "sonarqube",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/scorecard.md"
          ],
          "message": "Pre-existing evaluation output found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.66,
          "evidence": [
            "PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/llm_evaluation.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.22,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation decision meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 0.18,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/symbol-scanner/evaluation/results/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 0.22,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "symbol-scanner",
            "symbol-scanner"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.38,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 148.58,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.43,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.57,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.11,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.06,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.08,
          "evidence": [
            "input: $(EVAL_OUTPUT_DIR)/output.json"
          ],
          "message": "evaluate target input path is valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.55,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.39,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.11,
          "evidence": [
            "call_relationship.py",
            "import_completeness.py",
            "integration.py",
            "symbol_accuracy.py"
          ],
          "message": "LLM judge count meets minimum (4 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 8.63,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: call_relationship.py",
            "prompt: call_relationship.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.17,
          "evidence": [
            "metaprogramming.json",
            "csharp-tshock.json",
            "cross-module-calls.json",
            "deep-hierarchy.json",
            "encoding-edge-cases.json",
            "circular-imports.json",
            "js-cross-module-calls.json",
            "type-checking-imports.json",
            "decorators-advanced.json",
            "dynamic-code-generation.json",
            "async-patterns.json",
            "nested-structures.json",
            "class-hierarchy.json",
            "simple-functions.json",
            "generators-comprehensions.json",
            "dataclasses-protocols.json",
            "ts-class-hierarchy.json",
            "deep-nesting-stress.json",
            "partial-syntax-errors.json",
            "unresolved-externals.json",
            "confusing-names.json",
            "modern-syntax.json",
            "large-file.json",
            "js-simple-functions.json",
            "web-framework-patterns.json",
            "import-patterns.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 0.45,
          "evidence": [
            "timestamp",
            "decision",
            "score",
            "checks",
            "summary",
            "aggregate",
            "per_repo_results",
            "metadata",
            "regression"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.41,
          "evidence": [
            "PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.02,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.08,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.06,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.05,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.26,
          "evidence": [
            "src/sot-engine/dbt/models/staging/stg_lz_code_symbols.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.14,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 3.21,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 161.54,
          "evidence": [
            "Fixture: symbol_scanner_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.63,
          "evidence": [
            "paths",
            "ranges",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.88,
          "evidence": [],
          "message": "Adapter SymbolScannerAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.33,
          "evidence": [
            "Found 1 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.21,
          "evidence": [],
          "message": "Tool 'symbol-scanner' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.28,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.24,
          "evidence": [
            "stg_symbol_calls_file_metrics.sql",
            "stg_symbols_file_metrics.sql",
            "stg_symbol_coupling_metrics.sql",
            "stg_lz_symbol_calls.sql",
            "stg_lz_code_symbols.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 13.47,
          "evidence": [
            "CodeSymbol",
            "SymbolCall",
            "FileImport"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 1.01,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 26.43,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.5,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "symbol-scanner",
      "status": "pass"
    },
    {
      "checks": [
        {
          "check_id": "run.analyze",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Pre-existing analysis output found",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/scorecard.md",
            "WARNING: Output is 15 days old (threshold: 14 days)"
          ],
          "message": "Pre-existing evaluation output found (stale)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.quality",
          "duration_ms": 0.21,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Evaluation decision meets threshold",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "run.evaluate_llm",
          "duration_ms": 0.0,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/evaluation/llm/results/synthetic-llm-eval.json"
          ],
          "message": "Pre-existing LLM evaluation output found",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_quality",
          "duration_ms": 0.18,
          "evidence": [
            "score=4.0"
          ],
          "message": "LLM evaluation score meets threshold",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.load",
          "duration_ms": 1.64,
          "evidence": [
            "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools/trivy/outputs/a03e871f-19b8-4728-aba8-eec58e9e0fb9/output.json"
          ],
          "message": "Output JSON loaded",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.paths",
          "duration_ms": 6.63,
          "evidence": [],
          "message": "Path values are repo-relative",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.data_completeness",
          "duration_ms": 0.2,
          "evidence": [],
          "message": "Data completeness validated",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.path_consistency",
          "duration_ms": 0.03,
          "evidence": [],
          "message": "No path fields found to validate",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.required_fields",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Required metadata fields present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_version",
          "duration_ms": 0.01,
          "evidence": [
            "1.0.0"
          ],
          "message": "Schema version is semver",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.tool_name_match",
          "duration_ms": 0.01,
          "evidence": [
            "trivy",
            "trivy"
          ],
          "message": "Tool name matches data.tool",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.metadata_consistency",
          "duration_ms": 0.01,
          "evidence": [],
          "message": "Metadata formats are consistent",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.version_alignment",
          "duration_ms": 0.44,
          "evidence": [
            "1.0.0"
          ],
          "message": "Output schema_version matches schema constraint",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "output.schema_validate",
          "duration_ms": 179.41,
          "evidence": [],
          "message": "Output validates against schema (venv)",
          "severity": "critical",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "structure.paths",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "All required paths present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.targets",
          "duration_ms": 0.36,
          "evidence": [],
          "message": "Makefile targets present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.permissions",
          "duration_ms": 0.02,
          "evidence": [],
          "message": "Makefile has correct permissions",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.uses_common",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "Makefile includes ../Makefile.common",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_dir_convention",
          "duration_ms": 0.1,
          "evidence": [
            "outputs/$(RUN_ID)"
          ],
          "message": "OUTPUT_DIR inherited from Makefile.common",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.output_filename",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "analyze target uses output directory argument",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "make.evaluate_input_valid",
          "duration_ms": 0.05,
          "evidence": [],
          "message": "No --results-dir/--analysis-dir/--analysis argument found in evaluate target",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.draft",
          "duration_ms": 0.11,
          "evidence": [],
          "message": "Schema draft is 2020-12",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "schema.contract",
          "duration_ms": 0.08,
          "evidence": [],
          "message": "Schema requires metadata and data fields",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.blueprint_structure",
          "duration_ms": 0.23,
          "evidence": [],
          "message": "BLUEPRINT.md has required sections",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "docs.eval_strategy_structure",
          "duration_ms": 0.56,
          "evidence": [],
          "message": "EVAL_STRATEGY.md has required sections",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.check_modules",
          "duration_ms": 0.13,
          "evidence": [],
          "message": "Check modules present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_prompts",
          "duration_ms": 0.1,
          "evidence": [],
          "message": "LLM prompts present",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_judge_count",
          "duration_ms": 0.14,
          "evidence": [
            "freshness_quality.py",
            "vulnerability_detection.py",
            "vulnerability_accuracy.py",
            "severity_accuracy.py",
            "iac_quality.py",
            "sbom_completeness.py",
            "false_positive_rate.py"
          ],
          "message": "LLM judge count meets minimum (7 >= 4)",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.synthetic_context",
          "duration_ms": 15.84,
          "evidence": [
            "base.py: evaluation_mode parameter present",
            "primary judge: vulnerability_accuracy.py",
            "prompt: vulnerability_accuracy.md has all placeholders"
          ],
          "message": "Synthetic evaluation context pattern implemented correctly",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.ground_truth",
          "duration_ms": 0.22,
          "evidence": [
            "dotnet-outdated.json",
            "js-fullstack.json",
            "vulnerable-npm.json",
            "iac-terraform.json",
            "no-vulnerabilities.json",
            "iac-misconfigs.json",
            "mixed-severity.json",
            "java-outdated.json",
            "critical-cves.json",
            "outdated-deps.json",
            "cfn-misconfigs.json",
            "k8s-misconfigs.json"
          ],
          "message": "Ground truth files present",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.scorecard",
          "duration_ms": 0.15,
          "evidence": [],
          "message": "Scorecard present",
          "severity": "low",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_exists",
          "duration_ms": 0.06,
          "evidence": [
            "evaluation/results/evaluation_report.json"
          ],
          "message": "Programmatic evaluation file exists",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_schema",
          "duration_ms": 1.04,
          "evidence": [
            "timestamp",
            "tool",
            "version",
            "decision",
            "score",
            "classification",
            "overall_score",
            "summary",
            "checks",
            "dimensions"
          ],
          "message": "Programmatic evaluation schema valid",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.programmatic_quality",
          "duration_ms": 0.59,
          "evidence": [
            "STRONG_PASS"
          ],
          "message": "Programmatic evaluation passed",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_exists",
          "duration_ms": 0.04,
          "evidence": [
            "evaluation/results/llm_evaluation.json"
          ],
          "message": "LLM evaluation file exists",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_schema",
          "duration_ms": 0.41,
          "evidence": [
            "timestamp",
            "model",
            "decision",
            "score",
            "programmatic_input",
            "dimensions",
            "summary",
            "run_id",
            "total_score",
            "average_confidence"
          ],
          "message": "LLM evaluation schema valid",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_includes_programmatic",
          "duration_ms": 0.12,
          "evidence": [
            "file=evaluation/results/evaluation_report.json",
            "decision=STRONG_PASS"
          ],
          "message": "LLM evaluation includes programmatic input",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.llm_decision_quality",
          "duration_ms": 0.09,
          "evidence": [
            "PASS"
          ],
          "message": "LLM evaluation passed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "evaluation.rollup_validation",
          "duration_ms": 0.27,
          "evidence": [
            "src/sot-engine/dbt/tests/test_rollup_trivy_direct_vs_recursive.sql"
          ],
          "message": "Rollup Validation declared with valid tests",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.compliance",
          "duration_ms": 0.07,
          "evidence": [],
          "message": "Adapter exposes schema, LZ contract, and validation hooks",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.schema_alignment",
          "duration_ms": 2.25,
          "evidence": [],
          "message": "TABLE_DDL matches schema.sql",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.integration",
          "duration_ms": 307.11,
          "evidence": [
            "Fixture: trivy_output.json"
          ],
          "message": "Adapter successfully persisted fixture data",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "adapter.quality_rules_coverage",
          "duration_ms": 1.04,
          "evidence": [
            "paths",
            "line_numbers",
            "required_fields"
          ],
          "message": "All 3 quality rules have implementation coverage",
          "severity": "info",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.adapter_registered",
          "duration_ms": 0.27,
          "evidence": [],
          "message": "Adapter TrivyAdapter properly registered in adapters/__init__.py",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.schema_table",
          "duration_ms": 0.26,
          "evidence": [
            "Found 3 table(s)"
          ],
          "message": "Schema tables found for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.orchestrator_wired",
          "duration_ms": 0.16,
          "evidence": [],
          "message": "Tool 'trivy' wired in TOOL_INGESTION_CONFIGS",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sot.dbt_staging_model",
          "duration_ms": 0.27,
          "evidence": [
            "stg_trivy_file_metrics.sql",
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt staging model(s) found",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "dbt.model_coverage",
          "duration_ms": 0.7,
          "evidence": [
            "stg_trivy_file_metrics.sql",
            "stg_trivy_iac_misconfigs.sql",
            "stg_trivy_vulnerabilities.sql",
            "stg_trivy_target_metrics.sql",
            "stg_trivy_targets.sql"
          ],
          "message": "dbt models present for tool",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "entity.repository_alignment",
          "duration_ms": 11.26,
          "evidence": [
            "TrivyVulnerability",
            "TrivyTarget",
            "TrivyIacMisconfig"
          ],
          "message": "All entities have aligned repositories",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.structure_naming",
          "duration_ms": 0.76,
          "evidence": [],
          "message": "Test structure and naming conventions followed",
          "severity": "medium",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "sql.cross_tool_join_patterns",
          "duration_ms": 31.77,
          "evidence": [],
          "message": "Cross-tool SQL joins use correct patterns (255 files checked)",
          "severity": "high",
          "status": "pass",
          "stderr_summary": null,
          "stdout_summary": null
        },
        {
          "check_id": "test.coverage_threshold",
          "duration_ms": 0.57,
          "evidence": [
            "coverage.json not found"
          ],
          "message": "No coverage report found - run with --run-coverage",
          "severity": "high",
          "status": "skip",
          "stderr_summary": null,
          "stdout_summary": null
        }
      ],
      "name": "trivy",
      "status": "pass"
    }
  ],
  "tools_root": "/Users/alexander.stage/Projects/2026-01-24-Project-Caldera/src/tools"
}